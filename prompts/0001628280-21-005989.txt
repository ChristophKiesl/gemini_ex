Prompt: Summarize the business model from the following text. Answer with a continuous text and with fivehundredtwelve tokens at max. Set your focus on sources of revenue , the intended customer base , products , distribution channels  and details of financing. Use only information from the following the text:

Item 1. Business
Overview 
We aim to enable exceptional scientific outcomes by commercializing transformative products for researchers to unlock deep, unbiased biological information. Our initial product, the Proteograph Product Suite (Proteograph), will leverage our proprietary engineered nanoparticle (NP) technology to provide unbiased, deep, rapid and large-scale access across the proteome. Our Proteograph Product Suite is an integrated solution that is comprised of consumables, an automation instrument and software. Our Proteograph solution provides an easy-to-use workflow, which has the potential to make proteomic profiling, and the analysis of the thousands of samples needed to characterize the complex, dynamic nature of the proteome, accessible for nearly any laboratory. We believe that characterizing and understanding the full complexity of the proteome is foundational for accelerating biological insights and will lead to broad potential end-markets for proteomics, encompassing basic research and discovery, translational research, diagnostics and applied applications. This full understanding of the complexity of the proteome requires large-scale, unbiased and deep interrogation of thousands of samples across time, which we believe is unavailable with the proteomic approaches available today. We believe that our Proteograph Product Suite has the potential to enable researchers to perform proteomics studies at scale, similar to the manner in which next generation sequencing (NGS) technologies have transformed genomics. 
Proteins are the functional units of all forms of life. While deoxyribonucleic acid (DNA) may be used as a static indicator of health risk, proteins are dynamic indicators of physiology and may be used to track health over time, gauge disease progression and monitor therapeutic response. Despite the central role proteins play in biology, the proteome is relatively unexplored compared to the genome, particularly the rich functional content that could be derived from large-scale proteomics studies. We believe large-scale characterization of the proteome has not been feasible with existing proteomics approaches, which broadly fall into two categories: (i) unbiased but not scalable, or (ii) scalable but biased. Current de novo, or unbiased, approaches require complex, lengthy, and labor- and capital-intensive workflows, which limit their scalability to small, under-powered studies, and require significant processing expertise. On the other hand, targeted or biased methods only enable interrogation of a limited number of known proteins per sample. Although biased approaches are scalable, they lack the breadth and depth necessary to appropriately characterize the proteome and catalog its many protein variants. Thus, we believe that proteomics researchers are forced into an unattractive trade-off between the number of samples in a study and the depth and breadth of the analysis. These trade-offs limit researchers’ abilities to advance characterization of the proteome to match the current characterization of the genome. We believe large-scale proteomic analysis is needed for a more complete understanding of biology.
Much like NGS enabled large-scale access to the genome and transformed science and medicine, we believe that widespread access to unbiased and deep proteomics will lead to novel biological insights, deepen understanding of health and disease, and aid functional characterization of genomic variants. We believe these capabilities appeal to a broad range of researchers and can lead to the creation of substantial end-market opportunities that may extend well beyond human health. We are initially focused on driving adoption of our Proteograph with customers in proteomics and genomics markets, who see the value of large-scale, unbiased, deep proteomics. Allied Market Research estimates the proteomics market was $32 billion in 2019. We believe that our Proteograph’s unique capabilities will enable researchers to undertake studies not possible today, particularly those of larger scale. We also believe that our Proteograph solution will complement genomics technologies by adding critical missing information that can provide functional context to genomic variation. According to the dbSNP database, approximately 695 million individual genetic variants have been identified to date; however, fewer than 0.2% of those variants have been cataloged in the ClinVar database with a reported relationship between variation and phenotype. We believe unbiased, deep and large-scale proteomics can help researchers map biological function of genomic variants, identify the most impactful disease and response-specific risk factors, and accelerate discovery of molecular mechanisms of health and disease. We believe these capabilities will broadly appeal to researchers and entities undertaking large-scale genomics studies. Therefore, we believe we will attract spending from the genomics market, estimated by Technavio to be $21 billion in 2019. In addition to the markets and applications that apply to 
1


current proteomics and genomics researchers, we believe our Proteograph is likely to lead to entirely new applications and market opportunities, much like NGS has done in genomics over the last fifteen years. 
We plan to initially focus on research applications for our Proteograph Product Suite and will sell and market it for research use only (RUO). We plan to commercialize our Proteograph Product Suite utilizing a three phase plan that has been shown to be effective and optimal for introducing disruptive products in numerous life sciences technology markets, including NGS. We are currently in the first phase, during which we will collaborate with a small number of key opinion leaders in proteomics, whose assessment and validation of products can significantly influence other researchers in their respective markets. Our first Proteograph was delivered to one of our first collaborators in October 2020, a second Proteograph to another collaborator in December 2020 and a third Proteograph to a third collaborator in March 2021. In consideration of our initial collaborators’ significant contributions to the development of our Proteograph Product Suite, including providing us with helpful data and feedback on our Proteograph, we have offered our early collaborators a special discount program for consumables that is not reflective of our expected commercial pricing. Additionally, we have provided these early collaborators with the ability to purchase our SP100 automation instrument at a discount following the completion of the first phase of our commercialization plan. During the second phase, early access limited release, which we expect to commence in 2021, we plan to sell our Proteograph to select sites performing large-scale proteomics or genomics research. We will work closely with these sites, which we expect will serve as models for the rest of the market, to exemplify applications that demonstrate the unique value proposition of our Proteograph. We expect this phase to continue through 2021 and lead into the third phase of commercialization, broad commercial availability, in early 2022. During the second and third phases, we expect to sell our Proteograph Product Suite at list prices though we may offer volume-based discounts on consumables, consistent with industry practice. We believe by following this approach we can appropriately scale our operations, deliver exceptional customer experiences, foster publications and develop a robust pipeline of customers to drive our revenue growth.
The Importance of Proteomics
Proteomics has been a key area of focus for researchers given the utility of the detailed and complex information to understanding biology that resides at the protein level. Virtually every function within a living organism occurs by the action of a protein or a group of proteins interacting with each other and working in concert. For example, enzymes catalyze chemical and biochemical reactions, hormones regulate cellular processes, receptors facilitate signal detection, antibodies provide immunity, and proteins also function in cellular and sub-cellular structure, storage, motility, and transport processes. Proteins are dynamic indicators of status and can be used to track a person’s health, disease progression and therapeutic response. By contrast, DNA is effectively a blueprint of what a person’s physiology could be, not an indicator of current physiological state. In short, DNA represents risk and proteins represent status. 
Despite the impact that proteins have on biology and physiology, the human proteome is relatively unexplored compared to the human genome. While the understanding of biology and disease mechanisms has advanced significantly over the past decade through large-scale data collection technologies, we believe these advances have mainly been in genomics. The widespread adoption of molecular profiling techniques, including NGS, has led to the identification of approximately 695 million genetic variations across all genomes that have been sequenced. Although this information has significantly improved the understanding of biology, the functional context at the protein level has not been established for the vast majority of this genomics information. In other words, researchers have not been able to connect phenotypic information with the relevant genotypic information. We believe that if we enable researchers to generate large bodies of proteomic data, to couple with large bodies of genomic data, they will be better positioned to understand the relationship between variation and function and its impact on biology. 
2


Challenges of Accessing the Proteome
The human proteome is dynamic and far more complex and diverse in structure, composition and number of variants than either the genome or transcriptome. Starting from the genome, there are multiple biological steps that take place to arrive at the proteome, each step driving increasing complexity and diversity. The human genome of approximately 20,000 genes is estimated to give rise to 1,000,000 or more protein variants, in part because a single gene produces distinct ribonucleic acid (RNA) isoforms through the process of transcription and a myriad of structurally distinct proteins through the process of translation. Biological processes can further chemically modify these proteins in unique ways, resulting in a large number of protein variants through post-translational modifications. Overall, these processes result in many levels of protein diversity, from amino acid sequence and structural variations, to post-translational modifications (PTMs), to functional changes due to interactions between the proteins themselves, known as protein-protein interactions (PPIs). In addition, all of these forms of diversity can differ between states of health and disease. We believe the fundamental challenge with existing proteomics methods is their inability to measure the breadth and depth of the proteome’s complexity, rapidly and at scale. 
Image from Isabell Bludau et al. Proteomic and interactomic insights into the molecular basis of cell functional diversity. Nature Reviews Molecular Cell Biology (2020). 
3


Limitations of Biased Approaches to Proteomics
Unlike DNA, proteins’ structures, chemistries and concentrations in any given sample are widely variable. Proteins also lack a direct amplification mechanism which creates technological challenges for identifying proteins at low concentration. This is different than DNA, which has an inherent and direct amplification mechanism for its replication, a mechanism that researchers have exploited with technologies such as polymerase chain reaction (PCR) for detection of DNA at low concentrations. Given the diversity of protein structures, coupled with the lack of a common amplification mechanism, researchers often use analyte-specific reagents (ASRs) to measure proteins. ASRs are ligands, such as antibodies, that have been designed to bind to specific areas of proteins, and therefore, involve a targeted or biased approach. This biased approach is limited in that ASRs do not have the capability to interrogate the entirety of the protein structure that they bind to and may not detect the presence of important protein variants. The average length of a human protein is approximately 470 amino acids, whereas the average binding site of an ASR is an epitope with a length of five to eight amino acids. ASRs cannot recognize differences between proteins outside of this small epitope binding site and therefore may not differentiate among protein variants. While a large number of ASRs can be designed to detect a large number of different proteins, because this approach is limited in its ability to measure protein variation, we believe that ASRs and other biased approaches are not optimal for discovery given the inherent protein complexity. This limitation of biased approaches is illustrated in the figure below where an antibody is unable to differentiate between two distinct variants of the same protein. If such variants are differentially related to health and disease, such approach may fail to discover important insights. Biased approaches, in general, are useful when the scientist or clinician knows what he or she is specifically analyzing. This is analogous to the role of PCR in genomics, which amplifies a specific DNA fragment in a targeted or biased manner to confirm the presence of a specific mutation, whereas NGS employs an unbiased approach to interrogate the breadth of the genome. 
Limitations of Current Unbiased Approaches to Proteomics
Rather than interrogating proteins at the amino acid level, there are unbiased approaches that interrogate proteins at the peptide level, providing amino-acid level resolution to protein variants. However, current unbiased approaches are limited by lack of scalability due to the vastly different concentrations of different proteins in samples. The concentration of proteins in plasma, for example, can span ten orders of magnitude from the most abundant protein, which is albumin, to some of the least abundant proteins, such as cytokines. The top 22 most abundant proteins account for approximately 99% of the total protein mass in the plasma, yet the many thousands of less abundant proteins comprising the other one percent of the total proteins by mass have significant impact on 
4


biology. Therefore, it is critical to be able to broadly and deeply detect proteins across the proteome, including those proteins that appear in low concentrations in plasma.
Mass spectrometry (MS) can be used as an unbiased or biased detection technology, and has been used for detection of proteins and their variants for unbiased discovery, biased research and clinical applications. Given the varying dynamic range of protein concentrations in plasma and other biological samples, current MS methods for proteomic detection require complex sample preparation workflows that involve depletion of abundant proteins and grouping of the remaining proteins into smaller units through fractionation in order to measure deeper into the proteome. We believe current unbiased approaches are not widely adopted by researchers because the workflows, protocols and unit operations are extremely complex, the process is expensive and the time required to complete such analysis is significant. As one example of these complex methods, in a paper from Keshishian, H. et al., the researchers first depleted the most abundant proteins with immuno-affinity columns and then separated the remaining proteins by many subsequent and complex chromatographic steps and mass spectrometer injections. This approach identified 4,500 different proteins, but only across 16 samples. The study took multiple months to complete. 
The critical unmet needs in proteomic analysis remain how to collect unbiased proteomic data on thousands of proteins in a sample spanning more than ten orders of dynamic range in concentration and how to do so in thousands of samples at a reasonable cost and in a reasonable amount of time. Genomics faced a similar unmet need before the advent of NGS, which allowed for massively parallel sampling.
Background of Massively Parallel Sampling 
The ability to perform massively parallel sampling in biology has been transformational to researchers’ ability to perform large-scale and unbiased biological analysis. For example, before NGS, genomic approaches were not scalable to either read the entire genome or process very large numbers of samples. Researchers could only sequence hundreds of fragments of DNA or RNA at a time, and not easily in parallel. Genetic analysis was limited to biased, shallow genetic studies that were time-consuming and not scalable. As a result, researchers in genomics faced similar challenges that researchers currently face in proteomics. The introduction of NGS enabled massively parallel sampling of small fragments of DNA, allowing researchers to, in parallel, sequence tens of millions, and, through subsequent innovations, currently tens of billions, of fragments of DNA per sample. This transformative approach to sampling enabled genomic sequencing technologies to scale and created the path to genomic end-market opportunities, including basic research and discovery, translational research and clinical applications, including early cancer detection, recurrence monitoring and non-invasive prenatal testing. While there are no assurances that our 
5


Proteograph will have the same effect on the proteomics market as NGS technologies have had on the genomics market, given the utility of proteins for measuring function, health and disease, we believe the same, if not a greater, market opportunity exists for providing unbiased, deep, rapid and scalable access to the proteome. 
Our Proprietary Engineered Nanoparticle Technology 
Our proprietary engineered NP technology overcomes the limitations of existing methods and is the foundation for our Proteograph Product Suite’s easy-to-use workflow for unbiased, deep, rapid and scalable proteomic analysis. Our approach is based on proprietary engineered NPs that enable unbiased and massively parallel sampling of intact proteins across the proteome, capturing a myriad of molecular information at the level of protein variants as well as PPIs. Our NPs are designed to eliminate the need for complex workflows required by other unbiased approaches, which we believe will make proteomics more accessible to the broader scientific community. 
The diameter of a nanoparticle is typically in the tens to hundreds of nanometers. As a reference, the diameter of the human hair is 80,000 nanometers. When nanoparticles are placed in contact with a biological sample, a thin layer of intact proteins rapidly, selectively and reproducibly adsorbs onto the surface of a nanoparticle upon contact, forming what is called a protein “corona.” Additional intact proteins can also join the corona layer by binding directly to a protein that has already attached to the nanoparticle through PPIs and intact protein complexes may also attach to the nanoparticle directly. Our NPs’ ability to capture whole and intact proteins and their many diverse variants provides access to protein structural information, including information on PPIs. At binding equilibrium, which occurs within minutes after our NPs come into contact with the protein, the selective sampling of proteins by our NPs is robust and highly reproducible. 
The protein sampling and binding of proteins to the nanoparticle surface are driven by three primary factors: (i) affinity of a given protein for a given nanoparticle’s physicochemical surface; (ii) concentration of a given protein in a biological sample; and (iii) affinity of the proteins for other proteins on the surface of the nanoparticle, forming PPIs. We can use a variety of different methods and materials to design and create different nanoparticles. Each nanoparticle can have distinct physicochemical properties that generate a unique protein corona pattern and a unique proteomic fingerprint. We can combine nanoparticles into panels to provide a representative and thorough sampling across the dynamic range of the proteome, from high to low abundance proteins. In effect, the properties of protein binding to a panel of nanoparticles are functionally equivalent to, and can replace, complex, biochemical laboratory workflows for the preparation of samples for deep, unbiased MS, and which enable the capture of thousands of proteins from biofluids for large-scale proteomics studies. Virtually any solubilized biological sample can be interrogated with nanoparticles, including cell or tissue homogenates, blood or blood components (such as plasma or serum, urine), saliva, cerebrospinal fluid and synovial fluid. The versatility of nanoparticles provides the opportunity to use a vast universe of different nanoparticles with different physicochemical properties to selectively, reproducibly and deeply sample the proteome in an unbiased way. 
6


The figure below illustrates the dynamic range of the proteome with high abundance proteins in the upper left of the curve and low abundance proteins in the lower right of the curve. Each of our unique nanoparticles has different physicochemical properties, which allows it to sample selectively across the breadth of the proteome.
Our NPs enable the unique capabilities of our Proteograph Product Suite, including the ability to:
•eliminate complex biofluid processing workflows required by other unbiased proteomic approaches;
•sample in an unbiased manner across the dynamic range of the proteome in a variety of biological samples, including cell or tissue homogenates, blood or blood components (such as plasma or serum), urine, saliva, cerebrospinal fluid, and synovial fluid;
•identify and distinguish protein variants at the peptide level;
•identify and quantify protein variants and PPIs;
•use machine learning to design, synthesize and select different NPs and NP panels to create multiple products and applications; and 
•be compatible across a wide range of laboratory workflows, automation equipment and sample processing and detection methods, lowering the hurdle for product adoption.
We have validated our NP technology and the principle of protein corona formation as a robust and reproducible method to deeply and broadly profile the proteome in a high-throughput manner. In our recent publication in Nature Communications (Blume et al.), we demonstrated a rapid, deep and precise profiling of the plasma proteome with our proprietary engineered NP technology.
Our Proteograph Product Suite
Our proprietary engineered NP technology forms the basis for our first product, the Proteograph Product Suite. Our Proteograph is an integrated solution consisting of consumables, an automation instrument and software to perform unbiased, deep proteomic analysis at scale in a matter of hours. We designed our Proteograph workflow to be efficient and easy-to-use, and to leverage broadly-used laboratory instrumentation to enable adoption in both decentralized and centralized settings and be widely available to life sciences researchers. 
Our Proteograph consumables consist of our NP panel and all other consumables necessary to assay samples on our SP100 automation instrument. Our SP100 automation instrument is custom-configured for researchers to assay samples in approximately seven hours, which includes thirty minutes of set-up time and six and a half hours of automated instrument time. The output from our SP100 automation instrument is peptides ready to be processed on an MS instrument, which is a widely-accessible platform for protein detection. The Proteograph Product Suite is 
7


detector agnostic and, therefore, we believe, will be adaptable to other protein detection instruments in the future. The MS component of our Proteograph workflow is either provided by the researcher’s laboratory or can be outsourced to a third-party provider. We estimate that there are approximately 16,000 MS instruments with configurations typically used to perform proteomic analysis installed worldwide and, therefore, we believe that MS systems are readily accessible by researchers. Finally, we provide a data analytics software suite to analyze the output from the system that helps researchers interpret and gain insights into their data.

Consumables
For our first Proteograph assay, we will employ a panel of five NPs. Our Proteograph consumables also include buffers and reagents for protein lysis and digestion, peptide purification and peptide quantification. We designed the performance specifications of our Proteograph Product Suite to meet the core needs of the market in terms of protein coverage and sample throughput required for proteomic experiments that are unbiased and at-scale. The product will allow for the interrogation and processing of up to 16 samples by our five proprietary engineered NPs in parallel on a single 96-well plate in approximately seven hours. Eighty wells are arrayed in two groups of columns with eight samples and five particles in each column. The remaining 16 wells are for integrated quality control samples for gathering assay metrics and aid in troubleshooting. We include these quality controls because they greatly facilitate comparison of results across different assays, and also help to differentiate between anomalous versus accurate results in an assay. 
8


The ready availability of the non-particle reagents combined with our ability to efficiently and quickly design different NPs with different properties, greatly simplifies the development and production of future iterations or additional versions of our Proteograph assays to address potential customer needs, such as expanded coverage or specialized assays. Additionally, we can introduce new assays that include a different number of NPs and process different sample numbers. Our customers also can easily process the new assay using their existing SP100 automation instrument, which allows for a greater number of samples to be analyzed in parallel, or additional NPs to analyze the proteome at greater depth. 
Automation Instrument
We designed our NPs for robust performance in assays run on our SP100 automation instrument, which is a custom-configured industry-standard liquid handling workstation. Our SP100 instrument is designed to be robust and reproducible in its ability to consistently run experiments at the scale of hundreds to thousands of samples. Our instrument allows for rapid highly parallel proteomic sampling of multiple biosamples using multiple NPs on a 96-well plate. The assay protocol is fully automated after approximately thirty minutes of set-up time. The flexibility of our instrument, coupled with the inherent diversity of our NP technology, provides for many potential applications and study workflows that can suit particular experimental needs.
Our SP100 automation instrument has been configured to process one full 96-well plate at a time. For our first Proteograph assay this translates into processing 16 samples in parallel for each 96-well plate run. Our Proteograph Instrument Control Software (PICS) for the SP100 instrument is fixed and tailored to our specified workflow. Each new Proteograph assay will be able to run on our same SP100 automation instrument with a new NP panel and an accompanying software update. After an initial 30 minute set-up process, our first Proteograph assay runs for approximately six and one-half hours on our SP100 automation instrument. The output of our Proteograph assay and instrument is peptides that are quantified, dried, and reconstituted when ready to inject into a mass spectrometer for quantitative detection, either on an MS provided by the user or sent out for MS analysis to a third-party provider.
Software
Our Proteograph Analysis Suite was designed for ease-of-use and was developed to help users arrive at insights quickly and efficiently following peptide detection by an MS instrument. To accommodate varying customer needs, we have designed our Proteograph Analysis Suite to be deployed as cloud-based and, in the future, on-premise. Both deployment options will provide a predefined workflow for data management and analysis that leverages publicly available MS data analysis tools. Without our Proteograph Analysis Suite, the use of these tools requires expert knowledge and scalable high-performance computer infrastructure to run efficiently. We believe that our Proteograph Analysis Suite could accelerate adoption among non-proteomic experts by providing an intuitive user 
9


interface that automates and simplifies data handling, processing and analysis, and which provides access to a scalable infrastructure.
Another potential roadblock for researchers is understanding and evaluating the quality of their results. Our Proteograph assay incorporates a series of controls for monitoring quality of the assay. Our Proteograph Analysis Suite provides an integrated view of the results of these control runs. Using the Proteograph Analysis Suite, the customer can evaluate trends over time and implement performance boundaries around the expected values that flag unexpected outcomes in the data. Providing a simple, consistent interface for customers to evaluate the control data and generate a quality control (QC) report will help them understand our approach to QC in our Proteograph workflow and simplify support. Eventually, user communities might provide an avenue for customers to share their experiences against the backdrop of a common environment and understanding.
We expect that our Proteograph Product Suite will enable generation of large volumes of proteomic data, and we have developed our Proteograph Analysis Suite to ensure that handling, management and analysis of data does not create new bottlenecks for researchers. Our Proteograph Analysis Suite offers ease of implementation and addresses key customer needs, which include analysis of raw MS data with pre-configured parameters, integrated QC reporting, the ability to visualize and download the primary data analysis, and statistical analysis tools. Our Proteograph Analysis Suite is highly scalable and is designed to accommodate multi-instrument settings, rapidly expanding data volumes and emerging data analysis tools. Finally, as we continue to improve and extend our product portfolio, we expect to expand our Proteograph Analysis Suite to include advanced data analysis tools, including PPI analysis, mapping of PTMs, genetic polymorphisms, multi-omics integration, and systems biology framework analysis.
From Sample to Data Using our Proteograph Product Suite
Proteomic analysis using our Proteograph Product Suite has five primary steps:
1.Particle-Matrix Association. NPs can be mixed with a wide variety of soluble biological sample types (matrices), including cell or tissue homogenates, blood or blood components (such as plasma or serum), urine, saliva, cerebrospinal fluid, and synovial fluid. After combining the biosample and the NP, the mixture is incubated in a solution that mimics physiological conditions, producing protein-corona on the surface of the NPs.
2.Protein Corona Wash. NPs are then captured by a magnetic field, after which they undergo repeated cycles of wash with buffer to remove unbound, or loosely bound, proteins. 
3.Peptide Preparation. Washed NPs are subject to enzymatic digestion to generate peptides, which are collected, quantified, dried and ready for subsequent MS analysis. 
4.Mass Spectrometry. The researcher prepares the digested peptides for measurement by dissolution in appropriate peptide reconstitution buffer suitable for MS injection, at a volume and concentration that meets the researcher’s MS instrument and liquid chromatography gradient requirements.
5.Data analysis. After data acquisition, typical MS analysis methods are employed within our Proteograph Analysis Suite to identify and quantify the peptides and proteins in the sample. Quality control metrics are reported for the MS sample data, sample data summaries and output files are created, and initial cross-sample analyses are provided.
10


Given the seven-hour run time per plate for our initial five-NP panel, our Proteograph Product Suite could process 48 samples in a 24-hour period for unbiased and deep proteomic analysis. By comparison, the workflows developed by leading proteomics labs can take as long as several days to weeks, for sample preparation for MS measurement to reach an equivalent depth of proteomic coverage. 
Proteograph Product Suite Performance 
The four key technical attributes of our Proteograph Product Suite are its breadth of protein sampling, depth of coverage, accuracy and precision of measurement. In addition to its technical performance, our SP100 automation instrument’s rapid throughput is an important characteristic to scale the number of samples assayed. We believe that our Proteograph Product Suite is the only product to provide these technical and operational capabilities in an integrated solution to enable large-scale proteomic analysis. As described below, we discuss the performance of our first Proteograph assay relative to existing unbiased proteomics methods across the technical attributes of breadth, depth, accuracy and precision of measurement and the operational aspect of throughput. 
•Breadth of protein sampling. Breadth of protein sampling refers to our Proteograph Product Suite’s ability to conduct unbiased, highly parallel sampling of the proteome across its entire dynamic range, from high to low abundant proteins. Given the unique characteristics of our NPs, our Proteograph Product Suite allows for the unbiased highly parallel sampling of the proteome, and it does this across its entire dynamic range from high to low abundant proteins. Each uniquely engineered NP selectively captures hundreds of distinct intact proteins from a biosample based on their abundance and affinity for the NP surface. Our Proteograph 
11


solution leverages a panel of unique NPs to capture significantly more proteins and protein variants than current methods of unbiased proteomic analysis, as shown in the figure below. This advantage of our Proteograph Product Suite is particularly strong in complex biofluids such as plasma. 
As illustrated above, we compared our Proteograph Product Suite with other unbiased proteomics methods in a head-to-head experiment using the same biological sample. Neat plasma represents the simplest form of unbiased proteomic analysis, requiring minimal processing time, and resulted in a breadth of coverage of 312 proteins. By adding processing steps such as depletion of high abundance proteins and separation of the remaining proteins into multiple fractions (a process called fractionation), the breadth of protein sampling increased to 670 proteins. However, with our Proteograph solution, we detected 1,656 proteins in plasma, which represents a major expansion in breadth of protein coverage. 
•Depth of coverage. Depth of coverage refers to our Proteograph’s ability to evaluate the proteome across the wide dynamic range of abundance of proteins. The range from the most abundant to the least abundant protein in biological samples can vary greatly. In plasma, this range is estimated to be at least ten orders of magnitude, and the rich diversity of biology resides outside the most abundant proteins. Sampling across the entire dynamic range has been one of the seminal challenges in the field of proteomics. Conventional approaches to address this challenge have employed laborious depletion and fractionation methods, which can be avoided with the automated and scalable workflow of our Proteograph Product Suite. We compared the depth of coverage of our solution with other unbiased proteomic methods in a head-to-head experiment, shown in the figure below. Our Proteograph assay samples proteins across the entire dynamic range of the plasma proteome, as defined in the Human Plasma Proteome Project database (Schwenk et al.), with the 75th percentile point of depth of coverage shown with the orange bar. The depth of coverage for our 
12


Proteograph assay reaches further into the low abundant proteins than the fractionation, depletion and neat plasma methods.
•Accuracy of measurement. Accuracy refers to how close the measured abundance of a protein is to the true abundance in a sample. Accuracy of protein abundance measurement can be demonstrated by MS signal intensity of the proteins sampled with our Proteograph assay, and comparing these values with measurements obtained directly by immuno-assay (ELISA). In the below experiment, purified C-Reactive Protein (CRP) was added or “spiked” in to plasma at levels of 2x, 5x, 10x, and 100x of the baseline measured levels for CRP in the plasma. These samples with known concentrations of CRP were then interrogated with our Proteograph Product Suite and ELISA. The figure shows the linearity of measurement , as determined by MS signal intensity of four peptides within CRP when compared to the ELISA measurement of CRP. Our Proteograph assay can distinguish changes in protein abundance with significant accuracy, as demonstrated by a slope response approximately equal to one and an r-squared value greater than 0.95.
13


•Precision of measurement. Precision refers to how close several measurements of protein abundance in the same sample are to each other. Less precision in the measurement of a protein adds noise to an experiment, requiring a larger number of samples in the study to observe a true difference. Precision is typically measured as the coefficient of variation (CV%), or standard deviation divided by the mean times 100. Therefore, a lower CV% represents a more precise outcome. We compared the precision of our Proteograph solution with that of depletion, fractionation, and neat, by evaluating the same sample three times and calculating the CV% for the detected peptides and proteins. On average across the peptides, the median precision was 16.9 CV%. At this level of performance, our Proteograph has 80% statistical power to detect a 50% change in a peptide levels with only ten samples per sample group. Our analysis shows lower CV%s than fractionation and depletion methods, which is notable since we achieve lower CV%s while concurrently sampling significantly more proteins, as shown in the figure below. In general, in unbiased assays, CV%s are expected to increase as the number of analytes detected increases. However, our Proteograph assay can increase the number of analytes that it detects while achieving comparatively better CV%s. Although neat plasma has a lower CV%, it is limited in the breadth of protein coverage to 312 proteins compared to 1,652 proteins sampled by our Proteograph solution.
14


•Rapid and large-scale. Our Proteograph Product Suite enables rapid and large-scale proteomic sample processing in a seven-hour workflow, compared to other unbiased solutions that can take days to weeks. We reviewed major published plasma and serum proteomics studies from 2016 to 2019 to compare protein coverage, throughput and sample size. We have compared the results of 14 published unbiased, deep proteomics studies with the results from our recent Nature Communications paper (Blume et al.). While unbiased proteomics studies are vastly different in terms of their workflows, they may be considered more comparable in the quantifiable outputs of protein coverage, the amount of MS time required for the study and number of samples in the study. We only utilize the published MS time and did not account for up-front sample processing time. We examined these three outputs from the literature review against our published study. While we do not consider this to be a head-to-head comparison, it does provide general guidance to understand the comparative performance of our assay. We observed an average protein coverage of 1,960, with an average throughput of 1.5 proteins per minute, and average study size of 15 samples. This compares to our protein coverage of 2,094, a throughput of 14.2 proteins per minute, and study size of 141 samples. This advantage in throughput reflects only the MS time and does not include the additional throughput advantages of our SP100 automation instrument, which enables simpler and faster sample processing, which is otherwise also a lengthy part of unbiased studies. 
We believe that our studies demonstrate that our Proteograph Product Suite has a unique combination of attributes spanning breadth, depth, accuracy and precision of measurement and throughput necessary for large-scale proteomics studies. We believe our Proteograph solution will broadly appeal to researchers seeking an easy to use, scalable approach for such studies.

Markets
The proteome comprises millions of protein variants whose expression varies by cell, tissue, organ and system, as well as across time, and whose interaction with other proteins and biomolecules are essential to driving health and disease. No commercial product has existed that enables researchers to assess the proteome deeply, broadly, rapidly and at scale across thousands of samples. Despite this limitation, researchers rely on laborious, expensive and complex methods to survey as much of the proteome as they can. While NGS transformed life sciences end-markets through massively parallel access to the genome, lack of similar unbiased, deep, rapid and large-scale capabilities has to date evaded the field of proteomics. We believe our Proteograph Product Suite enables such access to the proteome, and will allow researchers to undertake the scale of studies we believe are needed to understand the complexity of the proteome, and by extension biology. 
We believe the two primary near-term markets for our Proteograph Product Suite are the proteomics market, which was $32 billion in 2019, according to Allied Market Research, and the genomics market, which was $21 billion in 2019, according to Technavio. Within these markets, potential applications of our Proteograph solution span basic research and discovery, translational research, diagnostics and applied applications. Of the $32 billion proteomics market, $25 billion is estimated to be spent on reagents, $5 billion on instruments, and $2 billion on services. In the near-term, we believe we will compete in both the proteomics reagent and instrument markets. Furthermore, the $21 billion genomics market consists of approximately $13 billion spent on products and $7 billion spent on services. In the near-term, we believe we will be able to garner spend from both products and services as genomic customers link genotype to phenotype by supplementing existing genomic data with proteomics data. While we initially plan to sell and market our Proteograph Product Suite for RUO, we believe that the capabilities of our Proteograph Product Suite may enable our customers to use our Proteograph in other applications. While we currently do not intend to pursue clinical diagnostics applications, we may in the future seek premarket approval or clearance for our Proteograph Product Suite in order to allow our customers to use our Proteograph in other product offerings. We believe that our Proteograph Product Suite’s unique value proposition will resonate with proteomics researchers who already value deep and unbiased proteomic information, and who desire to scale experiments to far greater sample sizes at a fraction of the time and cost of current approaches. We also believe that as more genomics researchers incorporate other -omics approaches to elucidate key genomic findings, our Proteograph will uniquely provide large-scale, unbiased and deep proteomic information to complement genomic information, and enable researchers to gain a clearer picture of biology and a deeper understanding of genomic risk factors. Longer-term, we believe that the capabilities offered by our Proteograph Product Suite and future products may potentially lead to new end-markets, applications, and business models that complement existing proteomics and genomics markets. 
15


Proteomics
Allied Market Research estimates the global proteomics market was $32 billion in 2019, and is expected to grow to $64 billion in 2024, representing a 15% compound annual growth rate. According to Allied Market Research, 60% of the proteomics market is focused on life sciences research, 35% for clinical applications and 5% other applications. Products in the proteomics market include spectrometry, microarray and chromatography instruments as well as reagents, used for both unbiased and biased proteomics. The majority of proteomic analysis to date either relies on biased or targeted methods or expensive, complex, and laborious unbiased or de novo deep methods that are applied only to tens of samples versus the thousands needed to power large-scale studies. Few methods are based on capture of intact proteins that enable analysis of proteome complexity at the level of amino acid variants, PTMs and PPIs, all of which have the potential to generate important biological insights. We believe the unique capabilities of our Proteograph Product Suite will appeal to researchers either as a complement or substitute for current approaches, or in creating an entirely novel path to survey the proteome. We estimate that there are approximately 16,000 MS instruments with configurations typically used to perform proteomic analysis installed worldwide. Since our Proteograph can leverage most MS instruments as a detector, we believe that we can take advantage of this installed base to accelerate adoption. We believe that we have an opportunity to provide a strong alternative to both unbiased and biased proteomics approaches, particularly in the discovery of new biology, and to grow the proteomics market by enabling new applications for unbiased proteomics. These applications currently span research, translational and clinical settings, and we believe that our Proteograph Product Suite can address all these applications over time. 
Genomics
Technavio estimates the global genomics market was $21 billion in 2019 and is expected to grow to $38 billion by 2024, representing a 13% compound annual growth rate. Over the last fifteen years, application of large-scale genomics across the population has led to discovery of approximately 695 million individual human variants and it is expected the total number of such variants will only expand as more exomes and genomes are sequenced. However, despite this impressive rate of variant discovery, fewer than 0.2% of those variants have been cataloged in the ClinVar database with a reported relationship between genetic variation and phenotype. We believe that large-scale deep, unbiased proteomics studies, such as those our Proteograph solution could enable, will provide important missing biological information to improve functional characterization of genomic variants. In genomics markets, 
16


complementing large-scale genomics analysis with large-scale proteomic analysis has the potential to enhance and accelerate our understanding of biology, human health and ultimately the treatment of disease. Therefore, we believe our Proteograph solution can appeal to an increasing number of genomics customers, especially those in translational settings, who are looking to leverage multi-omics approaches to further annotate genomic variants in terms of function and connect genotype to phenotype. 
New Markets
We also believe that our Proteograph Product Suite will enable novel applications and insights leading to new end-markets, similar to the impact that broad access to genomics products have had in creating new applications, end-markets and business models. For example, non-invasive prenatal testing and precision oncology currently make up a significant part of the current $21 billion genomics market, yet we believe that it would have been difficult to anticipate these market opportunities a decade ago. We believe the same dynamic of new market creation will occur in proteomics. One such application for proteomics is early disease detection. We spun out a new entity, PrognomIQ, Inc. (PrognomIQ), which aims to develop and commercialize novel diagnostic tests that leverage our Proteograph Product Suite in combination with genomics and metabolomics information, and will be a participant in the existing ecosystem of early disease detection. More broadly, we believe our Proteograph solution has the potential to further stimulate growth of new applications and end-markets in additional ecosystems. 
The Advantages of Our Proteograph Product Suite
We believe our Proteograph Product Suite and its underlying NP technology have the following advantages:
•Our Proteograph Product Suite is expected to be the first commercially available solution to provide the combination of unbiased, deep, rapid and large-scale access to the proteome. While other proteomics technologies exist today, we believe that our Proteograph Product Suite is the first and only product to provide the combination of these four attributes in a single integrated solution with an easy-to-use workflow. We believe these capabilities fill a gap that to date has been one of the rate-limiting steps in unlocking the complexity of biology. This creates a unique opportunity for us to drive widespread adoption of our solution, transform proteomics and biological research, and establish our Proteograph Product Suite as the industry standard for generating deep, unbiased proteomic information. 
•Our Proteograph Product Suite provides insight into protein variation and PPIs at a depth and scale that we believe sets a new standard for unbiased and deep proteomics, and is unattainable with other existing approaches. The ability to observe the myriad of possible protein variations, which go beyond simple total protein abundance, with the accuracy and precision necessary to extract useful insights across large numbers of subjects, is a key differentiating attribute of our solution. Furthermore, capturing these variations at scale enables synergistic insights when combined with genomic variations, finally enabling the development of informative, individualized models of biology at population scale. As noted in the figure above, biased 
17


approaches can capture individual proteins at scale, but are not readily able to capture protein variants at scale. Current unbiased approaches are able to capture some protein variants at the peptide level and can capture polymorphisms and PTMs, but not at scale. Moreover, these unbiased approaches are not able to capture PPIs and protein pathway information at scale. We believe that our Proteograph Product Suite is uniquely positioned to fully capture the breadth, depth and the complexity of the proteome at scale. 
•Our Proteograph Product Suite was designed to enable broad adoption across a wide variety of customers in both decentralized and centralized settings. Our Proteograph Product Suite is an integrated solution comprised of consumables, an automation instrument and software, and was designed to deliver ease-of-use, efficiency, robustness and reproducibility of results and to complement existing laboratory infrastructure. Our Proteograph’s simple and integrated workflow enables the customer to use their own MS instrument or leverage a widely available installed base of MS instruments . We estimate that there are approximately 16,000 MS instruments with configurations typically used to perform proteomic analysis installed worldwide. Since our Proteograph solution can leverage most MS instruments as a detector, we believe that we can take advantage of this installed base to accelerate adoption. We believe these characteristics will facilitate broad adoption of our Proteograph solution across a variety of laboratories and institutions in both decentralized and centralized settings.
•Our proprietary engineered NPs are a core technology from which we can develop a range of products, applications and platforms. We have evaluated over 275 different NPs with diverse sets of physicochemical properties, from which our five NPs for our first Proteograph assay were selected. From our growing and diverse NP library, we can develop new arrays of NP consumables that address a variety of applications and customer needs. We plan to use machine learning techniques and apply large-scale data analyses of our NP binding properties to understand relationships between NP surfaces and protein binding and interactions in order to rationally design our NP panels. Our NPs are versatile and can be designed to work with different sample types from plasma to homogenized tissue and collect proteomic, molecular and other -omics information. We believe these characteristics will enable development of additional differentiated products to enable our customers to utilize applications across the life sciences industry, ranging from basic research and discovery, translational research, diagnostics and applied applications.
•Our NP technology inherently provides significant operational leverage in research and development, manufacturing and commercialization. NPs are efficient to design, develop and manufacture. We believe we will be able to rapidly increase and deploy our understanding of NP design to develop new products with our software and data analytics capabilities. In the NP manufacturing process, we use well-characterized inputs and methods, which require relatively modest capital equipment and space investments. Since our core technology resides in the NP consumables, not the instrument, new products will often involve commercializing new NP assays and software that can be run on the existing instrumentation. This capital-efficient and labor-efficient model has the potential to provide significant operating leverage to our organization.
•Our Proteograph Product Suite has the potential to provide sustainable differentiation. Our Proteograph is uniquely capable of generating robust, reproducible, deep and unbiased proteomic data, and as more of this data gets created over our time and used by more customers to generate insights, we expect to create a virtuous cycle that will fuel further adoption of our Proteograph Product Suite throughout the industry. Our Proteograph workflow was designed to fully integrate with customer workflows and provide a unique user experience, supported by our software packages, to create a sustainable solution within our customers’ organizations. Our SP100 automation instrument, software, and NP technology are covered by numerous issued patents and pending patent applications, worldwide, covering improvements in NPs, assay methods and ways to leverage proteomic data and information for life sciences research and clinical diagnostic and drug discovery applications. 
18


Our Strategy
We aim to enable exceptional scientific outcomes by commercializing transformative products for researchers to unlock deep, unbiased biological information. Our growth strategy is to:
•Drive adoption of our Proteograph Product Suite to enable researchers to create large-scale unbiased proteomic datasets that generate transformative scientific insights. Our initial product, the Proteograph Product Suite, uniquely enables researchers and clinicians to generate unbiased, deep proteomic information at speed and scale which are not possible today. The utility and potential applications of these capabilities are broad, spanning across basic research and discovery, translational research, diagnostics and applied applications. We believe our first Proteograph assay is particularly well suited to address the core needs of researchers focused on basic and translational research and diagnostics. We intend to drive adoption of our Proteograph Product Suite through a three phase commercial launch plan that includes an initial collaboration phase with key opinion leaders, then an early access limited release phase in 2021 to initiate and build momentum of customer references, and finally broad commercial availability in early 2022.
•Invest in market development activities to increase awareness of the importance of large-scale proteomic data and the ability to access it. In order to expand and accelerate demand for our products, particularly as new applications are created and adopted by customers, we plan to invest in market development activities to educate prospective customers, funding bodies, commercial entities, government-sponsored -omics programs, and other stakeholders of the importance and value of large-scale unbiased and deep proteomic data. These activities will likely include collaborations with key opinion leaders, generation of peer-reviewed publications, sponsorship of targeted projects, joint publications and seminars, and industry partnerships. These activities aim to establish the value of large-scale unbiased and deep proteomic data, and demonstrate the unique capabilities offered by our products.
•Continually innovate to develop and commercialize additional transformative products to access the proteome and accelerate our understanding of biology. We aim to continually innovate and develop new products, applications, workflows and analysis tools that simplify and accelerate researchers and clinicians’ ability to generate proteomic data and to connect proteomic data to genomic and transcriptomic data that drive novel biological insights. As leaders in NGS have demonstrated, our sustainable advantage will come from continual development and commercialization of new products and applications based on our technology, and we will drive innovation through both internal R&D projects and from collaborations with customers and partners.
•Rapidly build our commercial infrastructure and NP manufacturing capabilities to provide for our commercial launch in the United States and internationally. We are initially building our commercial infrastructure to sell and support our products directly in the United States, the European Union and United Kingdom. We expect to expand access to our products in other geographies, starting with select countries in Asia Pacific through distributors, and eventually to the rest of the world. We are also scaling our NP manufacturing capabilities in our facility in Redwood City, California, and will continually evaluate and optimize our manufacturing and supply chain footprint to meet our business objectives.
•Foster the creation of an ecosystem of customers, partners and collaborators whose expertise and offerings complement and enhance the power and utility of our products. We intend to seed and develop a new ecosystem of applications and organizations that can take advantage of large-scale proteomic analysis. This ecosystem can include areas such as disease detection, large-scale population studies, agriculture, environmental monitoring and food safety. Much as we have seen large-scale genomic analysis spur new innovations in non-invasive prenatal testing, early cancer detection and recurrence monitoring, we believe large-scale proteomics will enhance these markets and spur the development of new markets and applications. To help seed the growth of this ecosystem, we spun-out a new company called PrognomIQ, which plans to develop and commercialize diagnostic tests for early disease detection, leveraging our Proteograph Product Suite in combination with other -omics technologies.
19


•Expand our proprietary engineered NP technology to analyze molecules beyond proteins. Given the inherent flexibility and ability to synthesize myriad NPs, we intend to seek over the long-term to expand the scope of our propriety engineered NP technology to analyze other biomolecules such nucleic acids, metabolites and small molecules among others. As we continue to work closely with our initial and future customers, we will better understand their needs and requirements, which will inform our product development pathway and development of our library of NPs and our software capabilities to address other -omics applications. We believe our management’s knowledge and experience in both the proteomics and genomics markets will position us to take advantage of such new expansion opportunities as they arise.
The Applications of our Proteograph Product Suite
We believe the ability to generate unbiased, deep proteomic data at scale, with rich content at the protein variant level will have broad applications in proteomics, encompassing basic research and discovery, translational research, diagnostics and applied markets. We believe this data will be used in many of the same application areas as are used with genomics data, proteomics applications that are uniquely possible with unbiased proteomic data, and in new applications that the field will develop in the future.
Basic Research and Discovery Applications
We believe that researchers will use our Proteograph solution for a variety of basic research and discovery applications, including cataloging protein diversity, proteogenomics and exploring the interactome. While researchers are pursing these applications today, the studies are either limited in scale due to the complex workflows of current unbiased methods or the limited set of ASRs that are available for biased methods. Our Proteograph Product Suite is designed to enable the use of unbiased proteomic data at scale, which we believe will greatly accelerate these areas of basic research and discovery.
Cataloging protein diversity
Our Proteograph Product Suite is designed to enable researchers to broadly explore the complexity and diversity of the proteome at the peptide and amino acid levels and discover many distinct protein variants. This is analogous to how NGS enabled genomic researchers to change their experimental focus from exploring genes to exploring exons and nucleotides, revealing approximately 695 million genetic variants to date. We expect that researchers will use our Proteograph solution to catalog these protein variants much like the cataloging of genetic variants that occurred over the past fifteen years, and this will uniquely provide functional context at a scale that is not accessible today with other proteomics methods. We believe the utility of these protein variants has the potential to impact a broad spectrum of the life sciences field.
The figure below shows the type of protein cataloging possible with our Proteograph Product Suite. Interrogating the protein data from our previously published work in Nature Communications (Blume et al.), we illustrate below that our Proteograph solution can identify a range of peptides for the proteins in plasma samples from lung cancer patients and healthy controls, which is not feasible or practical using a biased method. 
20


In the following figure, we have analyzed the Bone Morphogenic Protein 1 (BMP1) gene, which is known to have seven variants at the RNA level from alternative splicing and four variants at the protein level. Of these four variants, two are the long form and two are the short form of the BMP1 protein. Among the peptides that our Proteograph solution detected in this study, six specific peptides came from various parts of BMP1. Interestingly, the short form of the BMP1 protein was expressed predominantly in cancer patients, whereas the long forms of the protein were seen more often among the healthy controls. According to Pubmed, this observation has not been previously reported in the literature and may merit further investigation for the potential role of different BMP1 protein variants in health and cancer. We believe that researchers will therefore use our Proteograph Product Suite to pursue large-scale proteomics studies in order to generate data that may link disease biology to protein variants produced from alternative RNA splicing, alternative transcription and from PTMs.
21


In cataloging protein variants, researchers can also gain valuable insights with PTMs, such as phosphorylation. These PTMs are dynamic and the resulting protein variants can be seen with different states of health and disease. The figure below shows the differences in the ratio of phosphorylated to unphosphorylated states of a specific peptide within Heparin Co-factor 2 across 14 samples taken from each group of early and late stage lung cancer patients, healthy and comorbid controls. We show that the phosphorylation state of this peptide may vary as the disease state varies. Heparin Co-factor 2 has been previously shown to play a role in cancer and is associated with over-expression in lung cancer (Liao et al.). The phosphorylation observations below may merit further investigation for their roles in lung cancer. We believe that as researchers pursue large-scale proteomics studies, the literature that links disease biology to protein variants produced from alternative RNA splicing and from PTMs will exponentially increase.
Proteogenomics
Proteogenomics is an emerging area of research, whereby personalized protein sequence databases are generated using genomic and transcriptomic information to help identify novel peptides. In turn, the proteomic data provides functional context to genomic information and refines gene expression models for transcriptomic information. Our Proteograph solution generates large-scale unbiased proteomic data, which will facilitate mapping protein variants to genomic variants, and therefore, the advancement of the emerging proteogenomics field. As an example, we performed individual exon-based sequencing on 29 patient samples from our previously published proteomics work in Nature Communications (Blume et al.) to enable proteogenomic analysis on these samples and evaluate additional protein variants that could be revealed with the addition of genomic information. As shown in the left panel of the figure below, the sequencing information from these 29 samples, coupled to matching unbiased and deep analyses of the samples’ proteomic data using our Proteograph, yielded an average of approximately 70 predicted and confirmed peptide variations per sample. The right panel of the figure shows a subject who is heterozygous at the KLKB1 gene, which codes for the prekallikrein protein. This subject has both the reference allele for KLKB1 and a minor allele with a frequency of 0.01% in the population, resulting in a glycine to arginine amino acid change in the prekallikrein. Interestingly, we identified both prekallikrein variants in the plasma sample of this subject. Given the current level of access to genomic and transcriptomic information, as researchers conduct the large-scale proteomics studies that our Proteograph enables, we expect proteogenomic content to rapidly increase, providing functional information to existing genomics and gene expression information.
22


Interactome
The interactome refers to the broad set of interaction networks among molecules, such as those interactions among proteins, also referred to as protein-protein interactions, or PPIs. Protein interaction networks have been used to infer the function of proteins. Different types of interaction maps can be composed by the research community for different applications. These include physical interactions or the functional pathway implications of these interactions. PPI network maps can be constructed by pegging individual proteins as nodes and linking proteins that interact to them by a drawn line. These maps naturally cluster into hubs of proteins that fall into related pathways or have related functions.
We interrogated the plasma proteome of 276 subjects across early- and late-stage non-small-cell lung carcinoma (NSCLC), co-morbid and healthy controls. These subjects are a subset of those described in our Nature Communications publication (Blume et al.). Using proteins detected in these samples, we analyzed potential PPI interactions using the STRING PPI database (Szklarczyk et al.). In the figure below, we show a map of healthy versus early- and late-stage NSCLC where each protein is represented as a node and colored by its relative abundance. Green represents high abundance of proteins and red represents low abundance relative to the average abundance of the proteins across the samples. Multiple nodes can group together forming hubs with related common pathways or functions. Correlated changes in the abundance of proteins in these hubs may represent functional changes between health and disease. We highlight three hubs in the figure below with turquoise circles, and show changes depending upon health and disease state. Examination of the hubs can suggest biological hypotheses for the change in quantities. For example, the proteins in the central cluster are associated with Golgi vesicle transport, which is potentially linked to NSCLC. Access to the deep unbiased proteomic information provided by our Proteograph may enable researchers to better understand biological implications of known PPIs. Furthermore, given our highly parallel sampling of the proteome across multiple NPs and many samples, we believe researchers using 
23


the Proteograph Product Suite may be able to leverage machine learning methods on the resulting large data sets to derive novel PPIs. 
Translational Research Applications
Researchers can use our Proteograph solution to address translational research applications, which aim to shorten the cycle time from early discovery research to clinical application. Our Proteograph Product Suite allows clinical and translational researchers to conduct unbiased, deep and large-scale proteomics studies in therapeutic and diagnostic research and clinical trials, which can allow for significant advances in biomarker discovery, target identification and exploration, and clinical trial applications.
Biomarker discovery 
To date, most de novo biomarker discovery research is limited by the size of studies that can be done in an unbiased way, or limited to targeted studies that leverage existing knowledge. These approaches have yet to uncover the vast number of putative biomarkers that may be available as single markers or as combinations of markers for a range of clinical applications. We believe our Proteograph can greatly enable the discovery of biomarkers through large-scale, unbiased and deep proteomics studies.
The utility of our Proteograph Product Suite for exploration of potential biomarkers is illustrated in a proof-of-principle study in lung-cancer, as published in Nature Communications (Blume et al.). In this study, approximately 2,000 proteins were quantified across 141 subjects comprising early stage lung cancer (i.e., Stages 1, 2 or 3) and age- and gender-matched non-cancer controls. Machine-learning-based classifiers were developed. Plotting the sensitivity and specificity levels of our classifiers in a receiver operating characteristic (ROC) curve, we achieved a mean Area Under the Curve (AUC) of 0.91 on a scale from 1.0 (i.e., perfect) to 0.5 (i.e., random), as shown in the left panel of the figure below. In the right panel of the figure below, we show the most important classifiers in the study, with accompanying OpenTargets scores, where a score of one represents a validated target for a drug that is on-market, and a score of zero represents a target with no known target validation data in the literature. In our study, our Proteograph identified proteins with high OpenTargets scores such as tubulin 1-alpha and syndecin 1; the former is the molecular target for paclitaxel used in first-line therapy for NSCLC, and the latter is a molecular target for an antibody-drug conjugate, indatuximab ravtansine, currently in clinical trials for different cancer types. Our Proteograph identified proteins with low OpenTargets scores, and these could represent novel biomarker candidates for therapeutics and diagnostics development. A study of this size can be completed using our Proteograph in a fraction of the time of conventional methods, thus highlighting the efficiency of our Proteograph Product Suite in biomarker discovery studies.
24


Target Identification and Exploration
Currently FDA-approved drugs are directed to 754 separate human proteins that are directly related to the mechanism of action for the drug, and there are 4,009 genes in the UniProt database that have experimental evidence for being involved in disease. We believe that large-scale access to protein variant information that map to different states of health and disease, as enabled by our Proteograph solution and concurrent advances in proteogenomics, has the potential to lead to the discovery of personalized drug targets that could reach the hundred thousand range. We believe that the translational application of our Proteograph for potential biomarker development, as exemplified above in our NSCLC study, may also be applied to the identification of novel targets for therapeutic development. Components of classifiers may directly be targets themselves for drug development, or they may highlight new knowledge with respect to disease mechanism which then could help in the exploration of additional targets and/or help to elucidate the function of potential targets, particularly if these targets are discovered with genomics approaches, and lack protein functional context.
Clinical Trial Applications
Clinical researchers can use our Proteograph Product Suite for deep and broad proteomic profiling for subjects in therapeutic clinical trials, including to make observations on efficacy and adverse events. Applications could include the real-time monitoring of protein-related drug effects, distribution, and metabolism. Virtually all clinical trials in drug development include monitoring of this type, but currently use biased or targeted panels of proteins. It is currently impractical to do this type of monitoring with unbiased proteomic methods given the inability of these methods to scale to the hundreds or thousands of samples that are evaluated in clinical trials.
Our Proteograph Product Suite may also be used to select and group patients in clinical studies based on their proteomics profiles. As our understanding of the complexity of biology increases with new data accrued from our Proteograph as well as in adjacent -omics spaces, our ability to refine patient selection at a higher resolution may improve the ability to confirm efficacy for novel therapies, particularly in complex diseases that involve many inter-related physiological systems. Genomic approaches are widely used to select patients in cancer and rare genetic disease clinical trials, but the use of genomics-based selection for clinical trials outside of these indications has not been as widely used, given the relative lack of genetic understanding of these diseases. We believe that our Proteograph has the potential to generate useful proteomic signatures that can complement genomic and other patient selection criteria to improve how clinical researchers select and segment patients for these trials, particularly for indications outside of cancer and rare genetic diseases.
25


Diagnostic Applications
We see significant opportunities for researchers to use our Proteograph Product Suite for diagnostic development. Similar to the way in which NGS enabled the development of ecosystems that included genomics-based diagnostics in disease areas such as cancer and rare genetic diseases, we see the unbiased, deep and scalable proteomic information provided by our Proteograph solution potentially creating ecosystems, including proteomics and multi-omics based diagnostics in cancer and other complex disease areas. To help accelerate the future growth of this end-market, we spun-out a new company, PrognomIQ, that will leverage our Proteograph Product Suite to develop multi-omics tests for health and disease. We expect that PrognomIQ will be our customer. We expect that our Proteograph solution will be used by other companies in the healthcare testing space, and we will support all of these customers as the ecosystem grows. We plan to enable our customers by providing our Proteograph Product Suite for their basic research and translational research applications, as they develop their own diagnostic applications.
Applied Applications in Agriculture, Environmental and Food Safety 
Outside of the areas related to human health, we believe there are opportunities for our Proteograph solution to be applied in other applied applications, including those applications where broad scale genomics is being widely applied today, and other applications where proteomics can uniquely enable the creation of end-markets. We believe that unbiased, deep and large-scale proteomic information as enabled by our Proteograph can complement and extend the value of genomics, transcriptomics, and metabolomics information in fields such as agriculture, environmental monitoring and food safety. This is exemplified in a recent plant proteomics study that identified PPIs and multi-protein complexes that likely play a role in important agronomic traits.
Pathogen monitoring is a core research area in environmental sciences. Genomics-based approaches have been applied for environmental monitoring, and we believe that unbiased proteomic data can be used to complement genomic information in monitoring environmental pathogens.
The food industry has complex supply chains where food can be subject to contamination and spoilage in the food product itself as one moves from raw material to processing to distribution, storage and consumption of the food product. We believe that unbiased proteomic data from our Proteograph Product Suite could complement existing biochemical approaches for tracking signals of contamination and food spoilage. 
PrognomIQ 
In August 2020, we transferred certain assets related to disease testing to PrognomIQ, a wholly-owned subsidiary of the Company, in exchange for all of its outstanding equity interests. Following the transfer, we completed a pro-rata distribution to our stockholders of most of the shares of capital stock of PrognomIQ. Following the distribution and a subsequent $55.0 million financing of PrognomIQ, we hold approximately 19% of the outstanding equity in PrognomIQ.
The rationale for this transaction was to enable the growth of ecosystems around new applications that leverage unbiased, deep and large-scale proteomic information. The transaction allows us to remain focused on our core strategy, which is to be a provider, rather than a consumer, of proteomics solutions to all customers across these ecosystems. By focusing on our role as a provider of proteomics solutions, we are no longer potentially competing with, or creating the perception that we are competing with, our customers. Our relationship with PrognomIQ does not preclude us from selling our Proteograph Product Suite to any customer in any geography, nor does it preclude our customers from using our Proteograph in any way. PrognomIQ has indicated that it plans to combine the protein data from our Proteograph with genomics and other -omics data, to create a multi-omics approach to health and disease testing, which we believe will help us drive the adoption of our Proteograph Product Suite in these applications.
Omid Farokhzad, Chief Executive Officer and Chair of our board of directors, serves as the Chair of PrognomIQ’s board of directors. Philip Ma, Ph.D. our former Chief Business Officer serves as the Chief Executive Officer of PrognomIQ. While Dr. Ma has fully transitioned to PrognomIQ, he will remain our consultant until April 2021. In addition, three of our other employees have also transitioned to PrognomIQ. We will be providing general 
26


transition services and support, including laboratory and office space to PrognomIQ during the transition period. We anticipate these services to continue through the first half of 2021.
We granted PrognomIQ a non-exclusive license to certain patents and patent applications that we own and a non-exclusive sublicense to certain patent applications we exclusively licensed from The Brigham and Women’s Hospital, Inc. (BWH), in each case relating to our core technology, to develop, manufacture and commercialize licensed products for the field of human diagnostics on a worldwide basis. In consideration of the non-exclusive sublicense to certain patent applications licensed from BWH, PrognomIQ paid us a low-five digit figure, and would pay a low single digit royalty, in an amount equivalent to what we would have to pay under our license with BWH, on net sales of sublicensed products beginning with the first commercial sale of a sublicensed product during the term of the agreement. For further discussion of our license and sublicense arrangement with PrognomIQ, see the section titled “Business — Collaboration and License Agreements — PrognomIQ.” We do not view these amounts to be material to our financial condition and results of operations nor do we expect these amounts to ever be material to us in the future.
Commercial 
Commercial Strategy
Our Proteograph Product Suite is an integrated solution comprising consumables, an automation instrument and software. We have developed our Proteograph solution to simplify and accelerate proteomics workflow, reduce labor and capital requirements, and deliver robust and reproducible performance. We will focus on growing the installed base of our Proteograph across a wide variety of customer types and driving applications, scale of experimentation and discoveries that lead to increasing utilization of our Proteograph Product Suite by our customers. 
We intend to initially target potential customers who value unbiased and deep proteomic information and are performing proteomic or genomic analysis at academic institutions, translational research groups and biopharmaceutical companies. Our direct sales and marketing efforts will be focused on the principal investigators, researchers, department heads, research laboratory directors and core facility directors who control the buying decision. We expect these customers to purchase our SP100 automation instruments and associated consumables in line with typical purchases of other life science instrumentation and consumables. We intend to price our Proteograph Product Suite within the authorization range of most researchers who can directly make the buying decision, without the need for additional levels of approval, simplifying our sales process. For example, we intend to price our SP100 automation instrument on a comparable basis to other similar automated fluid handling systems currently available. We anticipate pricing our Proteograph consumables, on a per sample basis, in a range similar to that of other life sciences consumables that provide deep and unbiased -omic information.
We believe broad accessibility of MS instruments simplifies the adoption of our Proteograph Product Suite. We estimate that there are approximately 16,000 MS instruments with configurations typically used to perform proteomic analysis installed worldwide. We expect that many of our potential customers will have their own MS instrument, and for those who do not, will be able to outsource the MS portion of the Proteograph workflow to a third-party service provider. 
The generation of publications and scientific presentations is a core pillar of our market awareness strategy and is important for establishing validity and utility of new products in the life sciences community. We plan to work closely with our customers, including key opinion leaders, to generate clear use-cases, as well as peer-reviewed publications that illustrate our product performance claims and value proposition. In addition, we plan to drive awareness by developing and deploying online and in-person training and educational tools that explain our technology and key applications in easy-to-access, easy-to-understand, and scientifically rigorous and credible ways. We also expect to partner with select service facilities and core labs globally and certify them as Centers of Excellence for our Proteograph solution. We expect these sites will become our customers and potentially provide fee-for service capabilities that allow interested parties to evaluate our Proteograph Product Suite using their own samples. We expect that these Centers of Excellence will actively promote our Proteograph solution and its capabilities and help us further raise awareness.
27


To service our potential Proteograph customers, we will provide multiple levels of technical service for our SP100 automation instruments, depending upon customer need. We recognize that excellent customer support can be a critical part of a customer experience, and we will invest accordingly in our technical and application support to achieve the desired levels of service.
Proteograph Product Suite Commercial Launch Plan
We intend to follow a three phase launch plan to commercialize our Proteograph Product Suite. This approach has been successfully used to introduce transformative technologies in numerous life science sectors over many years, including in genomics with the roll-out of NGS products. We believe that this phased approach allows us to introduce the product in a measured way, demonstrate clear customer use-cases, help to ensure we are scaling and expanding in a way that delivers a positive and differentiated customer experience, and builds a prospective customer pipeline to provide visibility to future demand.
•Collaboration phase: We began collaborating with two sites in the third quarter of 2020 and we expect to collaborate with additional sites as we expand and continue this phase in 2021. Our first Proteograph was delivered to one of our first collaborators in October 2020, a second Proteograph to another collaborator in December 2020 and a third Proteograph to a third collaborator in March 2021. We plan to complement these initial collaborators with an additional collaborator in the genomics or multi-omics fields. We are targeting key opinion leaders who are highly-skilled at evaluating novel technologies and whose feedback can help us solidify our commercialization plans and processes. We will work with these collaborators to establish early models of impactful research and discovery that will highlight the unique capabilities and value proposition of our Proteograph. During this phase, we plan to provide our SP100 automation instrument for a minimal fee and also provide consumables at a reduced price. The sites will be given the option to purchase the SP100 automation instrument at a reduced price following the completion of the collaboration phase. 
•Early access limited release: We are entering the second phase of our commercial roll-out in 2021 in parallel with winding down the collaboration phase. In this second phase, we will expand to six to ten additional potential customers across our target segments, including key opinion leaders in proteomics as well those in genomics. We will primarily target customers who can scale quickly and demonstrate the power and utility of our Proteograph solution across a number of applications, such as discovery research, oncology, complex diseases, and proteogenomics. We believe these customers will become important reference sites and key influencers whose adoption of the technologies gives others a clear blueprint to follow. During this phase, we expect to broaden our commercial footprint to access and support an increasing number of customers and to set the foundation for the final phase of our commercial roll out. We plan to offer our Proteograph Product Suite to customers in the early access limited release phase at our proposed list price, with certain volume discounts for consumables consistent with industry standards. 
•Broad commercial availability: We intend to build on the momentum we expect to have created through both the collaboration and early access limited release phases of our roll-out to provide for broad commercial availability in early 2022. 
Commercial Organization
We are in the process of building out our commercial organization and we expect to have direct commercial staff in marketing, sales, customer success, and technical support functions. We will scale each function within our commercial organization in anticipation of demand and with the intent to deliver exceptional customer experience. We believe that coupling exceptional customer experience with a transformative product will allow us to deliver substantial value to our customers, build long-term customer loyalty, enhance our competitive differentiation, and, importantly, use our customer relationships to gain insights that inform our product development to grow our offerings in ways that will benefit our customers.
We expect to initially target customers in North America, the European Union and United Kingdom through direct sales and customer support organizations. We expect to grow into other geographies over time, initially through distributors, starting with key countries in Asia Pacific. We expect a highly efficient sales model since our 
28


Proteograph Product Suite does not have a large capital expenditure component, can leverage the existing installed base of MS instruments and complements large-scale genomics data ecosystems. 
Suppliers and Manufacturing
Our overall manufacturing strategy is to continuously develop and refine our processes to achieve our objectives of continuity of supply, quality of supply and margin enhancement. Over time, this may lead to in-sourcing or outsourcing certain functions, including manufacturing, in various geographic locations in order to achieve our objectives. 
Consumables
We leverage well-established unit operations to formulate and manufacture our NPs at our facilities in Redwood City, California. We procure certain components of our consumables from third-party manufacturers, which includes the commonly-available raw materials needed for manufacturing our proprietary engineered NPs. We are currently manufacturing using our pilot line and building out our manufacturing capabilities as we ramp towards broad commercial availability. We obtain some of the reagents and components used in our Proteograph workflow from third-party suppliers. While some of these reagents and components are sourced from a single supplier, these products are readily available from numerous suppliers. While we currently plan to handle filling and packaging of our Proteograph assay and the related consumables, in the future, we may have our filling and packaging outsourced to a third-party. We conduct vendor and component qualification for components provided by third-party suppliers and quality control tests on our NPs. 
Automation Instrument
We designed our SP100 automation instrument and have outsourced the manufacturing of our SP100 automation instrument to Hamilton Company, a leading manufacturer of automated liquid handling workstations. We have entered into a non-exclusive agreement with Hamilton that covers the manufacturing of our SP100 automation instrument and its continued supply on a purchase order basis. The agreement has an initial term that runs three years following our commercial launch. We have the option to extend the term of the agreement with Hamilton upon written notice at the end of the initial term; provided that prices are only fixed during the initial term of the agreement. Hamilton has represented to us that it maintains ISO 9001 and ISO 13485 certification. 
Competition
The life sciences technology industry is characterized by rapidly advancing technologies, intense competition and a strong emphasis on intellectual property. Today the proteomics market is served by companies that offer a variety of analytical instruments, such as chromatography and MS instruments, and associated reagents. We believe that competitors in the proteomics market are differentiated by their proprietary technologies, rapid product development capabilities, applications and intellectual property. We believe that there are currently no commercially available products that offer the capability to conduct unbiased, deep proteomics studies at the same scale and throughput as our Proteograph Product Suite. Given the potential market opportunity and scientific promise of proteomics, we expect the intensity of the competition to increase and, as a result, one or more competing products emerging in the future. Competing products may emerge from various sources, including life sciences tools, diagnostics, pharmaceutical and biotechnology companies, third-party service providers, academic research institutions, governmental agencies and public and private research institutions. 
Current companies that provide proteomics products include Agilent Technologies, Bio-Rad Laboratories, Danaher, Luminex, Merck (and its subsidiary MilliporeSigma) and Thermo Fisher Scientific. There are also a number of companies that provide proteomic analysis services. In addition, a number of emerging growth companies have developed, or are developing, proteomics products, services and solutions, such as Nautilus Biotechnology, Olink Proteomics, Quanterix and SomaLogic. 
29


Government Regulation
The development, testing, manufacturing, marketing, post-market surveillance, distribution, advertising and labeling of certain of medical devices are subject to regulation in the United States by the Center for Devices and Radiological Health of the U.S. Food and Drug Administration (FDA) under the Federal Food, Drug, and Cosmetic Act (FDC Act) and comparable state and international agencies. FDA defines a medical device as an instrument, apparatus, implement, machine, contrivance, implant, in vitro reagent or other similar or related article, including any component part or accessory, which is (i) intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, or prevention of disease, in man or other animals, or (ii) intended to affect the structure or any function of the body of man or other animals and which does not achieve any of its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of any of its primary intended purposes. Medical devices to be commercially distributed in the United States must receive from the FDA either clearance of a premarket notification, known as 510(k), or premarket approval pursuant to the FDC Act prior to marketing, unless subject to an exemption. 
We intend to label and sell our products for research purposes only (RUO) and expect to sell them to academic institutions, life sciences and research laboratories that conduct research, and biopharmaceutical and biotechnology companies for non-diagnostic and non-clinical purposes. Our products are not intended or promoted for use in clinical practice in the diagnosis of disease or other conditions, and they are labeled for research use only, not for use in diagnostic procedures. Accordingly, we believe our products, as we intend to market them, are not subject to regulation by FDA. Rather, while FDA regulations require that research use only products be labeled with – “For Research Use Only. Not for use in diagnostic procedures.” – the regulations do not subject such products to the FDA’s jurisdiction or the broader pre- and post-market controls for medical devices. 
In November 2013, the FDA issued a final guidance on products labeled RUO, which, among other things, reaffirmed that a company may not make any clinical or diagnostic claims about an RUO product, stating that merely including a labeling statement that the product is for research purposes only will not necessarily render the device exempt from the FDA’s clearance, approval, or other regulatory requirements if the totality of circumstances surrounding the distribution of the product indicates that the manufacturer knows its product is being used by customers for diagnostic uses or the manufacturer intends such a use. These circumstances may include, among other things, written or verbal marketing claims regarding a product’s performance in clinical diagnostic applications and a manufacturer’s provision of technical support for such activities. If FDA were to determine, based on the totality of circumstances, that our products labeled and marketed for RUO are intended for diagnostic purposes, they would be considered medical devices that will require clearance or approval prior to commercialization. Further, sales of devices for diagnostic purposes may subject us to additional healthcare regulation. We continue to monitor the changing legal and regulatory landscape to ensure our compliance with any applicable rules, laws and regulations.
In the future, certain of our products or related applications could become subject to regulation as medical devices by the FDA. If we wish to label and expand product lines to address the diagnosis of disease, regulation by governmental authorities in the United States and other countries will become an increasingly significant factor in development, testing, production, and marketing. Products that we may develop in the molecular diagnostic markets, depending on their intended use, may be regulated as medical devices or in vitro diagnostic products (IVDs) by the FDA and comparable agencies in other countries. In the U.S., if we market our products for use in performing clinical diagnostics, such products would be subject to regulation by the FDA under pre-market and post-market control as medical devices, unless an exemption applies, we would be required to obtain either prior 510(k) clearance or prior premarket approval from the FDA before commercializing the product. 
The FDA classifies medical devices into one of three classes. Devices deemed to pose lower risk to the patient are placed in either class I or II, which, unless an exemption applies, requires the manufacturer to submit a pre-market notification requesting FDA clearance for commercial distribution pursuant to Section 510(k) of the FDC Act. This process, known as 510(k) clearance, requires that the manufacturer demonstrate that the device is substantially equivalent to a previously cleared and legally marketed 510(k) device or a “pre-amendment” class III device for which pre-market approval applications (PMAs) have not been required by the FDA. This FDA review 
30


process typically takes from four to twelve months, although it can take longer. Most class I devices are exempted from this 510(k) premarket submission requirement. If no legally marketed predicate can be identified for a new device to enable the use of the 510(k) pathway, the device is automatically classified under the FDC Act as class III, which generally requires PMA approval. However, FDA can reclassify or use “de novo classification” for a device that meets the FDC Act standards for a class II device, permitting the device to be marketed without PMA approval. To grant such a reclassification, FDA must determine that the FDC Act’s general controls alone, or general controls and special controls together, are sufficient to provide a reasonable assurance of the device’s safety and effectiveness. The de novo classification route is generally less burdensome than the PMA approval process.
Devices deemed by the FDA to pose the greatest risk, such as life-sustaining, life-supporting, or implantable devices, or those deemed not substantially equivalent to a legally marketed predicate device, are placed in class III. Class III devices typically require PMA approval. To obtain PMA approval, an applicant must demonstrate the reasonable safety and effectiveness of the device based, in part, on data obtained in clinical studies. All clinical studies of investigational medical devices to determine safety and effectiveness must be conducted in accordance with FDA’s investigational device exemption (IDE) regulations, including the requirement for the study sponsor to submit an IDE application to FDA, unless exempt, which must become effective prior to commencing human clinical studies. PMA reviews generally last between one and two years, although they can take longer. Both the 510(k) and the PMA processes can be expensive and lengthy and may not result in clearance or approval. If we are required to submit our products for pre-market review by the FDA, we may be required to delay marketing and commercialization while we obtain premarket clearance or approval from the FDA. There would be no assurance that we could ever obtain such clearance or approval. 
All medical devices, including IVDs, that are regulated by the FDA are also subject to the quality system regulation. Obtaining the requisite regulatory approvals, including the FDA quality system inspections that are required for PMA approval, can be expensive and may involve considerable delay. The regulatory approval process for such products may be significantly delayed, may be significantly more expensive than anticipated, and may conclude without such products being approved by the FDA. Without timely regulatory approval, we will not be able to launch or successfully commercialize such diagnostic products. Changes to the current regulatory framework, including the imposition of additional or new regulations, could arise at any time during the development or marketing of our products. This may negatively affect our ability to obtain or maintain FDA or comparable regulatory clearance or approval of our products in the future. In addition, regulatory agencies may introduce new requirements that may change the regulatory requirements for us or our customers, or both.
As noted above, although our products are currently labeled and sold for research purposes only, the regulatory requirements related to marketing, selling, and supporting such products could be uncertain and depend on the totality of circumstances. This uncertainty exists even if such use by our customers occurs without our consent. If the FDA or other regulatory authorities assert that any of our RUO products are subject to regulatory clearance or approval, our business, financial condition, or results of operations could be adversely affected. 
For example, in some cases, our customers may use our RUO products in their own laboratory-developed tests (LDTs) or in other FDA-regulated products for clinical diagnostic use. The FDA has historically exercised enforcement discretion in not enforcing the medical device regulations against LDTs and LDT manufacturers. However, on October 3, 2014, the FDA issued two draft guidance documents that set forth the FDA’s proposed risk-based framework for regulating LDTs, which are designed, manufactured, and used within a single laboratory. In January 2017, the FDA announced that it would not issue final guidance on the oversight of LDTs and LDT manufacturers, but would seek further public discussion on an appropriate oversight approach and give Congress an opportunity to develop a legislative solution. More recently, the FDA has issued warning letters to genomics labs for illegally marketing genetic tests that claim to predict patients’ responses to specific medications, noting that the FDA has not created a legal “carve-out” for LDTs and retains discretion to take action when appropriate, such as when certain genomic tests raise significant public health concerns. As laboratories and manufacturers develop more complex genetic tests and diagnostic software, FDA may increase its regulation of LDTs. Any future legislative or administrative rule making or oversight of LDTs and LDT manufacturers, if and when finalized, may impact the sales of our products and how customers use our products, and may require us to change our business model in order to maintain compliance with these laws. We would become subject to additional FDA requirements if our products are determined to be medical devices or if we elect to seek 510(k) clearance or premarket approval. If our products 
31


become subject to FDA regulation as medical devices, we would need to invest significant time and resources to ensure ongoing compliance with FDA quality system regulations and other post-market regulatory requirements. 
International sales of medical devices are subject to foreign government regulations, which vary substantially from country to country. In the future, if we decide to distribute or market our diagnostic products as IVDs in Europe, such products will be subject to regulation under the European Union (EU) IVD Directive and/or the IVD Medical Device Regulation (IVDR) European Union (EU) 2017/746. The IVDR was published in 2017, will replace the IVD Directive, is significantly more extensive than the IVD Directive, including requirements on performance data and quality system, and will become fully enforceable in 2022. Outside of the EU, regulatory approval needs to be sought on a country-by-country basis in order to market medical devices. Although there is a trend towards harmonization of quality system, standards and regulations in each country may vary substantially which can affect timelines of introduction.
In August 2020, the Department of Health and Human Services (HHS) announced rescission of guidance and other informal issuances of the FDA regarding premarket review of LDT absent notice-and-comment rulemaking, stating that, absent notice-and-comment rulemaking, those seeking approval or clearance of, or an emergency use authorization, for an LDT may nonetheless voluntarily submit a premarket approval application, premarket notification or an Emergency Use Authorization request, respectively, but are not required to do so. The impact of this HHS rescission policy, including whether or how this policy will be implemented under the current administration, as well as other legislative, executive, and agency actions of the current administration remains unclear. The Biden administration has also issued a “regulatory freeze” memorandum that directs department and agency heads to review any new or pending rules of the prior administration. Any restrictions or heightened regulatory requirements on LDTs, IVDs, or RUO products by the FDA, HHS, Congress, or state regulatory authorities may decrease the demand for our products, increase our compliance costs, and negatively impact our business and profitability. We will continue to monitor and assess the impact of changing regulatory landscape on our business.
In the future, to the extent we develop any clinical diagnostic assays, we may pursue payment for such products through a diverse and broad range of channels and seek coverage and reimbursement by government health insurance programs and commercial third-party payors for such products. In the United States, there is no uniform coverage for clinical laboratory tests. The extent of coverage and rate of payment for covered services or items vary from payor to payor. Obtaining coverage and reimbursement for such products can be uncertain, time-consuming, and expensive, and, even if favorable coverage and reimbursement status were attained for our tests, to the extent applicable, less favorable coverage policies and reimbursement rates may be implemented in the future. Changes in healthcare regulatory policies could also increase our costs and subject us to additional regulatory requirements that may interrupt commercialization of our products, decrease our revenue and adversely impact sales of, and pricing of and reimbursement for, our products.
For further discussion of the risks we face relating to regulation, see the section titled “Risk factors—Risks related to our business and industry— Our products could become subject to government regulation as medical devices by the FDA and other regulatory agencies even if we do not elect to seek regulatory clearance or approval to market our products for diagnostic purposes, which would adversely impact our ability to market and sell our products and harm our business. If our products become subject to FDA regulation, the regulatory clearance or approval and the maintenance of continued and post-market regulatory compliance for such products will be expensive, time-consuming, and uncertain both in timing and in outcome.”
The federal Health Insurance Portability and Accountability Act of 1996 (HIPAA), as amended by the Health Information Technology for Economic and Clinical Health Act of 2009 (HITECH), and their implementing regulations, which impose obligations, including mandatory contractual terms, with respect to safeguarding the transmission, security and privacy of protected health information by covered entities subject to HIPAA, such as health plans, health care clearinghouses and healthcare providers, and their respective business associates that access protected health information. HITECH also created new tiers of civil monetary penalties, amended HIPAA to make civil and criminal penalties directly applicable to business associates in some cases, and gave state attorneys general new authority to file civil actions for damages or injunctions in federal courts to enforce the federal HIPAA laws and seek attorneys’ fees and costs associated with pursuing federal civil actions.
32


In addition, in the U.S., numerous federal and state laws and regulations, including state data breach notification laws, state health information privacy laws, and federal and state consumer protection laws, govern the collection, use, disclosure, and protection of health-related and other personal information. For example, in June 2018, the State of California enacted the CCPA, which came into effect on January 1, 2020 and provides new data privacy rights for consumers and new operational requirements for companies. While we are not currently subject to the CCPA, we may in the future be required to comply with the CCPA, which may increase our compliance costs and potential liability. Furthermore, the CCPA could mark the beginning of a trend toward more stringent state privacy legislation in the U.S., which could increase our potential liability and adversely affect our business.
Furthermore, the collection, use, storage, disclosure, transfer, or other processing of personal data regarding individuals in the European Economic Area (EEA), including personal health data, is subject to the GDPR, which became effective on May 25, 2018. The GDPR is wide-ranging in scope and imposes numerous requirements on companies that process personal data, including requirements relating to processing health and other sensitive data, obtaining consent of the individuals to whom the personal data relates, providing information to individuals regarding data processing activities, implementing safeguards to protect the security and confidentiality of personal data, providing notification of data breaches, and taking certain measures when engaging third-party processors. The GDPR also imposes strict rules on the transfer of personal data to countries outside the EEA, including the United States, and permits data protection authorities to impose large penalties for violations of the GDPR, including potential fines of up to €20 million or 4% of annual global revenues, whichever is greater. The GDPR also confers a private right of action on data subjects and consumer associations to lodge complaints with supervisory authorities, seek judicial remedies, and obtain compensation for damages resulting from violations of the GDPR. In addition, the GDPR includes restrictions on cross-border data transfers. The GDPR may increase our responsibility and liability in relation to personal data that we process where such processing is subject to the GDPR, and we may be required to put in place additional mechanisms to ensure compliance with the GDPR, including as implemented by individual countries. Compliance with the GDPR will be a rigorous and time-intensive process that may increase our cost of doing business or require us to change our business practices, and despite those efforts, there is a risk that we may be subject to fines and penalties, litigation, and reputational harm in connection with our European activities. Further, the United Kingdom’s decision to leave the EU, often referred to as Brexit, has created uncertainty with regard to data protection regulation in the United Kingdom. As of January 1, 2021, and the expiry of transitional arrangements agreed to between the United Kingdom and EU, data processing in the United Kingdom is governed by a United Kingdom version of the GDPR (combining the GDPR and the Data Protection Act 2018), exposing us to two parallel regimes, each of which potentially authorizes similar fines and other potentially divergent enforcement actions for certain violations. Pursuant to the Trade and Cooperation Agreement, which went into effect on January 1, 2021, the United Kingdom and EU agreed to a specified period during which the United Kingdom will be treated like an EU member state in relation to processing and transfers of personal data for four months from January 1, 2021. This period may be extended by two further months. Furthermore, following the expiration of the specified period, there will be increasing scope for divergence in application, interpretation and enforcement of the data protection law as between the United Kingdom and EEA.
For further discussion of the risks we face relating to regulation, see the section titled “Risk factors—Risks related to our business and industry— We are currently subject to, and may in the future become subject to additional, U.S., state and foreign laws and regulations imposing obligations on how we collect, store and process personal information. Our actual or perceived failure to comply with such obligations could harm our business. Ensuring compliance with such laws could also impair our efforts to maintain and expand our future customer base, and thereby decrease our revenue compliance with such laws could also impair our efforts to maintain and expand our future customer base, and thereby decrease our revenue.”
Intellectual Property 
Our success depends in part on our ability to obtain and maintain intellectual property protection for our products and technology. We use a variety of intellectual property protection strategies, including patents, trademarks, trade secrets and other methods of protecting proprietary information. 
33


As of December 31, 2020, our owned patents and patent applications, if issued, are expected to expire between 2023 and 2041, in each case without taking into account any possible patent term adjustments or extensions and assuming payment of all appropriate maintenance, renewal, annuity, or other governmental fees.
Such patent portfolio owned by us includes:
•pending U.S. and PCT patent applications that are directed to methods for sampling a proteome at specific levels of protein coverage, methods for sampling a proteome under particular assay conditions, and nanoparticle compositions for the same; 
•a pending PCT patent application that is directed to methods for interrogating protein pathways and PPIs with the biosensors;
•an issued U.S. patent and a pending U.S. patent application directed to the classification of biological states; and
•an issued U.S. patent and a pending PCT patent application directed to methods for biomarker discovery, including an algorithm-based method that uses data sampled by the biosensor platform.
We exclusively license three issued U.S. patents, six U.S. pending patent applications, one issued ex-U.S. patent and 11 ex-U.S. pending patent applications from BWH, as of December 31, 2020. These patents and patent applications are directed to methods for identifying a biological state, including classification and early detection of cancers and other diseases, using nanoparticle and biosensor compositions, as well as other nanoparticle compositions. Our in-licensed patents and patent applications, if issued, are expected to expire between 2027 and 2037, in each case without taking into account any possible patent term adjustments or extensions and assuming payment of all appropriate maintenance, renewal, annuity, or other governmental fees.
In addition to licensing patents and patent applications from BWH, we have also non-exclusively licensed certain of our patents and patent applications to PrognomIQ for use in the field of human diagnostics. Pursuant to our agreement with PrognomIQ, we also assigned a patent application related to lung cancer biomarkers to PrognomIQ. In connection with our agreement with PrognomIQ, we have granted PrognomIQ a non-exclusive sublicense to certain patents and patent applications that we license from BWH under our license agreement with BWH for use in the field of human diagnostics. For further information on the intellectual property transfer and license agreement with PrognomIQ and the license agreement with BWH, see the section titled “Business —Collaboration and License Agreements.”
We intend to pursue additional intellectual property protection to the extent we believe it would be beneficial and cost-effective. Our ability to stop third parties from making, using, selling, offering to sell, importing or otherwise commercializing any of our patented inventions, either directly or indirectly, will depend in part on our success in obtaining, defending and enforcing patent claims that cover our technology, inventions, and improvements. With respect to both our owned and in-licensed intellectual property, we cannot provide any assurance that any of our current or future patent applications will result in the issuance of patents in any particular jurisdiction, or that any of our current or future issued patents will effectively protect any of our products or technology from infringement or prevent others from commercializing infringing products or technology. Even if our pending patent applications are granted as issued patents, those patents may be challenged, circumvented or invalidated by third parties. Consequently, we may not obtain or maintain adequate patent protection for any of our products or technologies. 
In addition to our reliance on patent protection for our inventions, products and technologies, we also rely on trade secrets, know-how, confidentiality agreements and continuing technological innovation to develop and maintain our competitive position. For example, some elements of manufacturing processes, analytics techniques and processes, as well as computational-biological algorithms, and related processes and software, are based on unpatented trade secrets and know-how that are not publicly disclosed. Although we take steps to protect our proprietary information and trade secrets, including through contractual means with our employees, advisors and consultants, these agreements may be breached and we may not have adequate remedies for any breach. In addition, third parties may independently develop substantially equivalent proprietary information and techniques or 
34


otherwise gain access to our trade secrets or disclose our technology. As a result, we may not be able to meaningfully protect our trade secrets. For further discussion of the risks relating to intellectual property, see the section titled “Risk factors—Risks Related to our Intellectual Property.”
Collaboration and License Agreements
The Brigham and Women’s Hospital 
In December 2017, we entered into an exclusive patent license agreement with BWH, pursuant to which we obtained an exclusive, royalty-bearing, sublicensable (with approval from BWH) license to certain U.S. and foreign patents and patent applications in one patent family related to methods for identifying a biological state using nanoparticle and biosensor compositions and other nanoparticle compositions to develop, manufacture, use and commercialize products and processes in all fields, including but not limited to therapeutic, diagnostic, or other uses, on a worldwide basis. In addition, we were also granted an exclusive, royalty-bearing, sublicensable (with approval from BWH) license to certain U.S. pending patent applications in another patent family to develop, manufacture, use and commercialize products and processes in all fields, including but not limited to therapeutic, diagnostic, or other uses, other than for the treatment of cancer through antigen-specific immune stimulation or the treatment of disease through immune tolerance or immune switching of lymphocyte subclasses. We may sublicense the patent rights licensed under the agreement subject to certain conditions, including obtaining the review and approval by BWH of such sublicense and any such sublicense must be consistent with and subject to the terms of the agreement.
In consideration for the licenses granted under the agreement, we must pay BWH annual license fees prior to the first commercial sale of a licensed product that range in the low- to mid-five digit figures, and a low single digit royalty on net sales of licensed products beginning with the first commercial sale of a licensed product in any country during the term of the agreement. In the event we commercialize a product in the therapeutic space, we are also required to make certain drug-approval regulatory and commercialization milestone payments to BWH of up to a mid-seven digit figure in the aggregate for licensed products. In the event we sublicense any of the licensed intellectual property, we must pay BWH a percentage of any sublicense income received by us, which on a going-forward basis will be in the high single digits.
 Under the terms of the agreement, we are required to use commercially reasonable efforts to develop and commercialize the licensed products, including in accordance to certain developmental, funding, regulatory and commercialization milestones. BWH controls the prosecution, maintenance and enforcement of all licensed patents and patent applications under the agreement. 
Unless earlier terminated, the agreement continues until the expiration of the last to expire patent right licensed under the agreement. Subject to an applicable cure period, BWH may terminate the agreement if we fail to comply with applicable payments or diligence obligations or upon a breach of our obligation under the agreement, or for certain insolvency-related events. 
PrognomIQ 
In August 2020, we entered into an intellectual property transfer and license agreement and, in October 2020, we entered into an intellectual property sublicense agreement, in each case with PrognomIQ in connection with the spin-out of PrognomIQ. Under the intellectual property transfer and license agreement, we granted PrognomIQ a non-exclusive, perpetual, irrevocable (subject to termination for breach) license to certain patents and patent applications that we own and, under the intellectual property sublicense agreement, we granted a non-exclusive sublicense to certain patent applications exclusively licensed from BWH, in each case, relating to our core technology to develop, manufacture and commercialize licensed products for the field of human diagnostics on a worldwide basis. In addition, we assigned a patent application relating to lung cancer biomarkers, and transferred certain clinical samples, contracts and other related assets to PrognomIQ. PrognomIQ may extend such licensed and sublicensed rights to customers of licensed products. PrognomIQ is not required to pay us any royalties or fees pursuant to the intellectual property transfer and license agreement. In consideration of the non-exclusive sublicense to certain patent applications licensed from BWH, PrognomIQ paid us a low-five digit figure, and would pay a low single digit royalty, in an amount equivalent to what we would have to pay under our license with BWH, on net 
35


sales of sublicensed products beginning with the first commercial sale of a sublicensed product during the term of the intellectual property sublicense agreement. 
In the event we elect to grant an exclusive license to a third party in the field of human diagnostics for any of the patents and patent applications licensed or sublicensed, as applicable, to PrognomIQ under the respective agreements, we are required to first negotiate with PrognomIQ for a period of sixty days for a license or sublicense, as applicable, to such rights on reasonable terms. Furthermore, for a period of two years after the effective date, we are required to negotiate in good faith with PrognomIQ for a license or sublicense, as applicable, to any improvements to the patents and patent applications assigned or licensed or sublicensed, as applicable, under the intellectual property transfer and license agreement and the intellectual property sublicense agreement. 
Neither party may assign the intellectual property transfer and license agreement nor any rights or obligations under the agreement without the other party’s prior written consent, other than to an affiliate or pursuant to an acquisition. PrognomIQ may not assign the intellectual property sublicense agreement or any rights or obligations under the agreement without our prior written consent, other than to an affiliate or pursuant to an acquisition, and in any event only with BWH’s prior written consent. Our right to assign the intellectual property sublicense agreement and any rights or obligations under the agreement is subject to the terms and conditions of our license with BWH. Unless terminated earlier, the terms of the both agreements continue until the expiration of the last to expire intellectual property right granted under such agreement. Either party may terminate either agreement for an uncured breach of the other party, upon which all licenses granted under such agreement to the breaching party will terminate.
Collaborators
Oregon Health & Science University (OHSU), an academic health center, and The Broad Institute of MIT and Harvard (Broad Institute), a biomedical and genomic research center, are our collaborators. Researchers at OHSU are using our product to facilitate various research efforts focused on proteomic profiling of various oncology versus control samples to determine protein signatures common between various cancer samples versus signatures found in control samples. Researchers at the Broad Institute intend to use our product to analyze protein signatures in diseased vs. non-diseased samples undergoing drug perturbations in various clinical applications including cardiovascular disease.
In January 2021, Discovery Life Sciences, a biomedical and genomic research center, became one of our collaborators.
Scientific Advisory Board
We have assembled a highly qualified scientific advisory board composed of advisors who have deep expertise in the fields of nanotechnology, proteomics, genomics, medicine, regulatory compliance and data science. Our scientific advisory board is composed of Robert Langer, Sc.D., Mostafa Ronaghi, Ph.D., Steve Carr, Ph.D., Vivek Farias, Ph.D., Philip Kantoff, M.D., Erwin Böttinger, M.D., Charles Cantor, Ph.D., Bradley Hyman, M.D., Mark McClellan, Ph.D., M.D., Wolfgang Parak, Ph.D., Ralph Weissleder, M.D. and Luis Diaz, M.D.
Employees and Human Capital
As of December 31, 2020, we had 60 employees, all based in the United States, many of whom hold doctorate degrees. Of these employees, 45 were engaged in in research and development activities, and 15 were engaged in selling, general and administrative activities. None of our employees are represented by a labor union or covered under a collective bargaining agreement.
Our human capital resources objectives include, as applicable, identifying, recruiting, retaining, incentivizing and integrating our existing and new employees, advisors and consultants. The principal purposes of our equity and cash incentive plans are to attract, retain and reward personnel through the granting of stock-based and cash-based compensation awards, in order to increase stockholder value and the success of our company by motivating such individuals to perform to the best of their abilities and achieve our objectives.
36


Corporate Information and History
We were incorporated in Delaware on March 16, 2017, under the name Seer Biosciences, Inc., and changed our name to Seer, Inc. on July 16, 2018. Our principal executive offices are located at 3800 Bridge Parkway, Suite 102, Redwood City, California 94065. Our telephone number is 650-543-0000. Our website address is http://seer.bio. Information contained on, or that can be accessed through, our website should not be considered to be part of this Annual Report.
We use Seer and Proteograph as trademarks in the United States and other countries. This Annual Report contains references to our trademarks and service marks and to those belonging to other entities. Solely for convenience, trademarks and trade names referred to in this Annual Report, including logos, artwork and other visual displays, may appear without the ® or TM symbols, but such references are not intended to indicate in any way that we will not assert, to the fullest extent under applicable law, our rights or the rights of the applicable licensor to these trademarks and trade names. We do not intend our use or display of other entities’ trade names, trademarks or service marks to imply a relationship with, or endorsement or sponsorship of us by, any other entity.
Implications of Being an Emerging Growth Company
We are an “emerging growth company” as defined in the Jumpstart Our Business Startups Act of 2012, as amended, or the JOBS Act. We will remain an emerging growth company until the earliest to occur of: the last day of the fiscal year in which we have more than $1.07 billion in annual revenue; the date we qualify as a “large accelerated filer,” with at least $700 million of equity securities held by non-affiliates; the issuance, in any three-year period, by us of more than $1.0 billion in non-convertible debt securities; and the last day of the fiscal year ending after the fifth anniversary of our initial public offering. 
An emerging growth company may take advantage of reduced reporting requirements that are otherwise applicable to public companies. These provisions include, but are not limited to:
•not being required to comply with the auditor attestation requirements of Section 404 of the Sarbanes-Oxley Act of 2002, as amended;
•reduced disclosure obligations regarding executive compensation in our periodic reports, proxy statements and registration statements; and
•exemptions from the requirements of holding a nonbinding advisory vote on executive compensation and stockholder approval of any golden parachute payments not previously approved.
In addition, the JOBS Act provides that an emerging growth company can take advantage of an extended transition period for complying with new or revised accounting standards, delaying the adoption of these accounting standards until they would apply to private companies. We have elected to use this extended transition period to enable us to comply with new or revised accounting standards that have different effective dates for public and private companies until the earlier of the date we (i) are no longer an emerging growth company or (ii) affirmatively and irrevocably opt out of the extended transition period provided in the JOBS Act. As a result, our consolidated financial statements may not be comparable to companies that comply with the new or revised accounting standards as of public company effective dates.
To the extent that we continue to qualify as a "smaller reporting company," as such term is defined in Rule 12b-2 under the Securities Exchange Act of 1934, after we cease to qualify as an emerging growth company, we will continue to be permitted to make certain reduced disclosures in our periodic reports and other documents that we file with the SEC.
Available Information
We make our Annual Reports on Form 10-K, Quarterly Reports on Form 10-Q, Current Reports on Form 8-K, and amendments to those reports, available free of charge at our website as soon as reasonably practicable after they have been filed with the SEC. Our website address is http://seer.bio. Information on our website is not part of this report. The SEC maintains a website that contains the materials we file with the SEC at www.sec.gov.
37


