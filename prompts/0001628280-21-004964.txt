Prompt: Summarize the business model from the following text. Answer with a continuous text and with fivehundredtwelve tokens at max. Set your focus on sources of revenue , the intended customer base , products , distribution channels  and details of financing . Use only information from the following text

Item 1. Business
Overview
Velodyne, the first pure-play lidar company, is a global leader in lidar technology providing real-time 3D vision for autonomous systems. Our lidar solutions are advancing the development of safe automated systems throughout the world, thereby empowering the autonomous revolution by allowing machines to see their surroundings. In automotive applications, our products improve roadway safety by providing perception data for reliable object avoidance and safe path-planning. To improve roadway, bicycle, and pedestrian safety, we sell automotive solutions to the rapidly expanding Advanced Driver Assistance Systems (“ADAS”) market, which will incrementally address the requirements of the National Highway Traffic Safety Administration (“NHTSA”) 5-Star Safety Ratings System.
Our lidar-based smart vision solutions are also deployed in many non-automotive applications, including autonomous mobile robots, unmanned aerial vehicles (“UAV”)/drones, last-mile delivery, precision agriculture, advanced security systems, and smart city initiatives. In the past, purchases of our solutions in these markets have been primarily focused on research and development projects. We are now seeing growth within this sector of the industry as many of our non-automotive customers move into commercial production with their offerings. 
Through our direct sales team as well as through distributors, we sell to both automotive customers, including top automotive OEMs, system integrators, and last-mile delivery providers, as well as to non- automotive customers providing an array of industrial, drone, and security applications, among others. 
We believe that our lidar technologies can significantly reduce the number of lives lost in vehicle crashes and substantially reduce pedestrian and bicyclist fatalities. Beyond the automotive industry, our technology can also help reduce injuries in areas including factories, construction sites, mines, oil rigs and ports. Lidar technology can also enhance public welfare through security and smart city applications. In addition, our solutions are being used in applications such as touchless delivery, sanitation and physical distance tracking, all of which have advanced safety and health measures during the COVID-19 pandemic.
Business Combination
Graf Industrial Corp. (“Graf”), our predecessor, was originally incorporated in Delaware as a special purpose acquisition company. On July 2, 2020, Graf and VL Merger Sub Inc., a wholly owned subsidiary of Graf entered into a merger agreement with Velodyne (the “Merger Agreement”). We refer to the transactions contemplated by the Merger Agreement as the “Business Combination.” Graf consummated the Business Combination on September 29, 2020. Immediately upon the consummation of the Business Combination, the pre-combination Velodyne became a wholly-owned subsidiary of Graf. Graf changed its name to Velodyne Lidar, Inc. and the pre-combination Velodyne Lidar changed its name to Velodyne Lidar USA, Inc. On September 30, 2020, Velodyne Lidar’s common stock and warrants began trading on the Nasdaq Global Select Market under the symbol “VLDR” and “VLDRW,” respectively.
The aggregate consideration for the Business Combination and related transactions was approximately $1.8 billion, consisting of (i) $222.1 million in cash at the closing of the Business Combination, net of transaction expenses, and (ii) 150,277,532 shares of common stock valued at $10.25 per share, totaling $1,540.3 million. 
Our Technology Platform
Our hardware and software solutions center around our proprietary lidar sensor technology, which enables real-time, three-dimensional vision of the surrounding environment for a breadth of autonomous and intelligent systems.
To perceive the environment in 3D, our sensor emits a series of laser pulses, typically millions of pulses each second, which bounce off objects in the environment and return to the sensor. The device measures the time each pulse traveled and uses highly sophisticated, real-time algorithms to create digital, machine-readable maps of the surrounding environment. These maps have up to centimeter-level precision and capture rich detail all around the sensor. Since the maps are continually refreshed every few milliseconds, they can be used to perceive both static and dynamic objects. Unlike cameras that are two-dimensional and radar that is not capable of high-definition imaging, our lidar captures a precise, high definition, three-dimensional view of the environment. These characteristics make our lidar technology the ideal sensor platform for cars, robots and other autonomous machines to perceive the world as they move through it. 
Our Product Portfolio
Using an array of eye-safe lasers, our lidar solutions measure distances in the environment at the speed of light. Unlike camera-based solutions, lidar solutions allow machines to see in 3D by providing precise distance measurements of surrounding objects. Lidar also performs better than cameras in low light conditions and produces fewer errors. Compared to radar, lidar provides better resolution, perceiving objects’ shapes for superior object detection and classification. Lidar also performs better than cameras in darkened conditions and produces fewer errors. Lidar systems currently being tested can detect pedestrians equally well during daytime and nighttime conditions because the systems provide self-illumination by means of laser beams. Together with lower computing power requirements, these features enable autonomous platforms to make fast and accurate decisions to mitigate collisions. Velodyne’s proprietary lidar-based hardware and software solutions combine class-leading range, up to centimeter-level accuracy and lower power consumption with high-grade reliability.
Surround View Lidar
We offer a broad lineup of surround-view lidar to support numerous end applications, including autonomous vehicles, drones, security, and mapping. 
VLS-128 (Alpha Prime) is our flagship surround-view lidar and the first sensor in the world capable of 300-meter range, specifically made for autonomous driving and advanced vehicle safety at highway speeds. The lidar sensor incorporates 128 lasers and provides real-time 3D data up to 0.1-degree vertical and horizontal resolution. The Alpha Prime provides the best combination of range, resolution and precision to enable Level 4 and Level 5 autonomous vehicles to function both at highway speeds as well as in low-speed urban environments. We were recognized with the Pace Automotive Award for this product.
VLP-32 (Ultra Puck) is the third generation of the Puck family. The high-density, long-range image generated by the Ultra Puck makes it an optimal solution for robotics, mapping, security, driver assistance and autonomous navigation. VLP-32 uses 32 lasers to double the range and resolution of its predecessor at a range of up to 200 meters. Ultra Puck also introduces firing exclusion and advanced features for minimizing false positives. The compact design is small and light enough to be placed below a car’s side-view mirror and greatly reduces the cost of the system required for a fully-autonomous vehicle.
VLP-16 (Puck) is one of the most popular sensors on the market and offers 16 lasers and a 100 meter range. Developed with mass production and affordability in mind, the Puck retains the multi-laser design of our other sensors while offering lower power consumption, lighter weight and a more compact footprint at an attractive price point, making it ideal for low speed autonomy and driver assistance applications.
VLP-16 Hi-Res (Puck Hi-Res) is a further iteration of the original groundbreaking Puck and is designed for applications requiring high image resolution. While retaining surround view and 100 meter range, this sensor compresses the vertical field-of-view from 30 degrees to 20 degrees for a tighter laser distribution spaced at 1.33 degrees instead of 2.00 degrees. This design delivers more details in the 3D image at longer ranges and enables the host system to not only detect but also better identify objects at these greater distances. It is optimized for autonomous vehicle applications but will provide denser data and better object recognition in all its applications.
VLP-16 LITE (Puck LITE) is the world’s lightest 16-laser lidar sensor at 590 grams and was designed expressly to address the exacting requirements of the UAV and aerial 3D mapping markets. Puck LITE achieves identical performance to the original Puck but reduces the sensor weight by almost 30 percent, critically enabling longer flight times. This lightweight, high-performance sensor retains 360-degree surround view to capture real-time 3D lidar data.
HDL-32E was released in response to demand for a more compact and lighter sensor and this second-generation 3D lidar solution extends the core 360-degree technology developed for the HDL-64E. The HDL-32E features 32 lasers aligned over a 40-degree vertical field-of-view, generates up to 1.39 million points per second and was the first 3D lidar technology to provide distance and intensity measurements across 100 meters with less than 2-centimeter accuracy. More compact and lighter weight than its predecessor, the HDL-32E measures 5.7 inches high by 3.4 inches wide, weighs less than 2 kilograms and is developed to meet stringent military and automotive environmental specifications.
HDL-64E was the world’s first commercially available real-time 3D lidar, supporting 64 lasers, a 360-degree field-of-view and a 120 meter range. The HDL-64E is based on the first prototype invented by David Hall, our former director and CEO, and to date has been driven millions of miles on public roads across the United States. Designed for robust obstacle detection this sensor continues to enable safe navigation of ground vehicles, such as heavy trucks and autonomous fleets, in ports, and on marine vessels.
Solid State Lidar
Our solid state lidar technology combine the high reliability and long lifetime of traditional micro electro-mechanical systems (“MEMS”) solutions while also providing longer sensing range.
Velarray M1600
Designed for autonomous applications in sidewalk, commercial and industrial settings, the Velarray M1600 provides outstanding near-field perception at a range of 0.1 to 30 meters for safe navigation in diverse environmental conditions. The Velarray M1600’s optimal combination of data-rich resolution and broad field-of-view enables precise mapping and obstacle avoidance. With a durable design, this sensor is aesthetically well-suited for external mounting and easily embeddable in a robot’s sensor compartment. The Velarray M1600 features our breakthrough micro-lidar array (“MLA”) architecture, a robust and reliable design for mass production.
Velarray H800
With the Velarray H800, we deliver the optimal solid state lidar sensor for ADAS and autonomous applications. The H800’s range – from .01 to 200 meters – combined with wide horizontal field of view (“FOV”) detects objects early enough to enable safe stopping distances in urban driving scenarios and collision avoidance on curves and turns. Its excellent vertical FOV provides superior detection of near-range small and overhead objects, while covering corner use-cases including sloping roads. The H800’s range enables advanced highway ADAS features such as Adaptive Cruise Control, Lane Keep Assist, and Automatic Emergency Braking. With a configurable frame rate, the H800 offers outstanding point cloud density for high resolution mapping and object classification tasks. Designed for automotive-grade performance and durability, this versatile sensor is ideal for a variety of internal and external mounting locations. The Velarray H800 also features our breakthrough MLA architecture.
Products under Development
The following products are under development and are not yet available for commercial shipment to customers. There are risks associated with developing and producing these new products. See Item 1A: “Risk Factors—Risks Related to Velodyne’s Business—The markets in which Velodyne competes are characterized by rapid technological change, which requires it to continue to develop new products and product innovations, and could adversely affect market adoption of its products.”
Solid State Lidar
Velabit will bring Velodyne’s performance and design to an embedded solution that can be hidden around or inside the vehicle. Aimed at satisfying a growing set of price-sensitive applications, Velabit will retain 100 meter range and high precision while being packaged in our smallest form factor. The Velabit will be our lowest-priced sensor.
Dome Lidar
Our dome hybrid solid state architecture has an innovative optical design that provides a 180-degree, hemispherical view of the surrounding environment in an embeddable form factor to enable detection of objects in close proximity, such as pedestrians and bicyclists.
VelaDome will be a category-creating sensor specifically designed for high-resolution, short- range sensing. The VelaDome will offer 180-degree by 180-degree field-of-view and the ability to detect objects as close as 0.1 meter. The VelaDome’s small form factor will fit for a variety of low profile mounting and styling options along the sides of an autonomous vehicle. This sensor’s near-field detection and high-density image will make it an ideal solution for a range of close-proximity automotive applications, including blind-spot monitoring.
Software Solutions
Vella
As part of our mission to drive commercial adoption, we are also developing a full software ADAS solution built around lidar, which we refer to as Vella. The Vella software solution is designed to deliver a rich set of safety and autonomy applications to any vehicle that utilizes a Velarray lidar. For automotive applications, Vella interprets lidar point cloud data to perform obstacle detection and tracking for avoiding and mitigating crashes with dynamic and static objects, including vulnerable road users and vehicles. Through predictive collision monitoring, Vella compares an object’s trajectory with that of the ego vehicle, in order to identify and avoid imminent crash scenarios. 
We believe this will provide an opportunity for us to monetize our data assets, providing us with a potential new source of revenue through a data and software services model.
Customers, Sales and Distribution 
We currently have, and are actively developing, several multi-year contracts for ADAS and autonomous vehicle programs. We work closely with major autonomous vehicle development programs around the world. In addition, companies across a wide range of non-automotive end markets are increasingly adopting our lidar-based technologies into their systems. Our customers deploy our smart vision technology in various applications across markets, including in autonomous vehicles, ADAS, UAVs, mapping, industrial automation, self-driving rovers, autonomous vessels, smart city initiatives and robotics. Additionally, we provide account management, product management, and technical support experts to form deep, collaborative relationships with strategic customer research and development organizations. These teams focus on assisting with rapid first installations, mass production supply agreements and post-sales support.
In 2020 and 2019, more than 300 customers, including distributors who sell our products to additional end customers, purchased lidar solutions from us. Approximately 200 of those customers were in non-automotive markets. In 2020 and 2019, two customers each accounted for more than 10% of our revenue. We define the number of customers as the number of customers for which we have received an order for one or more of our products. A single organization or customer may represent multiple customers due to separate divisions, segments or subsidiaries.
We have various multi-year agreements with customers, including non-automotive customers and automotive customers such as OEMs and system integrators. These agreements generally provide for one-year demand forecasts, with quarterly volumes and prices for the year. After the first year, we and the customer have the ability to evaluate need and price for subsequent forecasts. These agreements provide unit discounts for both volume commitments and marketing commitments. These multi-year agreements also provide terms and conditions of sale that are negotiated based on price and volume commitment. We are actively developing several such agreements with potential non-automotive and automotive customers.
We have built an extensive ecosystem in the markets we serve. We have distribution partners in Asia and Europe to address growing market opportunities in these regions and beyond. In North America, we sell directly to most of our customers as well as through three national distributors who are also our customers and integrators. We also sell our solutions through our customer service hubs around the world, such as Germany and China, where we maintain offices and staff.
Manufacturing
We have dedicated teams focused on manufacturing processes, such as those that include proprietary alignment and calibration techniques. Our teams leverage automation steps to lower manufacturing times, improve yield and position us and our manufacturing partners to produce at increasing scale as our customers’ requirements increase. We expect to reduce our focus on in-house manufacturing and increasingly leverage the experience of our current and future manufacturing partners. Currently, our two key manufacturing partners are Nikon and Fabrinet. We plan to expand these manufacturing partnerships 
in 2021 to include VLS-128 and Velarray by transferring these products currently manufactured in-house to Nikon and Fabrinet, respectively.
Industry and Competition
There is an increasing demand for lidar to help advance automated systems with the goal of increasing safety, improving efficiency and enhance productivity. Lidar’s status as a critical sensor in many applications gives us the opportunity to add higher value to customers by providing comprehensive solutions. There is increasing adoption of lidar across a wide variety of industries, some of which are accelerating in a post-COVID world. 
For the automotive industry, SAE International has published a taxonomy with detailed definitions for six levels of driving automation, ranging from no automation to full automation. To increase road safety and respond to regulatory requirements, we believe automotive manufacturers are proactively adopting ADAS technology. As industry participants develop active safety features, standards defining the increasing levels of sophistication in these features are required. We are working with SAE International and other major professional and standardization organizations to guide the relevant regulations that address public safety.
Additionally, we believe businesses are actively exploring the use of autonomous trucks, drones and robots to help create more efficient and less expensive delivery infrastructure to meet consumer demand for fast and cost-efficient delivery solutions. As a result, we believe there is a continual need for precise 3D mapping information to understand the surrounding environment and movement patterns to improve transportation logistics and enhance traffic efficiency.
The market for perception solutions for autonomous applications is an emerging market, with many potential applications in the development stage. As a result, we face competition from a range of companies seeking to have their products incorporated into these applications that are being developed and it may take a long period of time for our primary competitors to emerge. Our competitors are also working to advance technology, reliability, and innovation in their development of new and improved solutions. Although we believe that we have market leading technology, we continue to face competition from existing competitors and new companies emerging in the lidar, camera and radar industries. It is our belief that it will take most of these new smaller companies a substantial period of time to gain the recognition and trust of top-tier automotive OEMs, as well as customers and partners in other non-automotive industries. For example, we believe that we shipped more units in the fourth quarter of 2020 than all of our other competitors combined for the year. Many of our competitors offer products targeted for niche applications. Some competitors are currently selling products that offer lower levels of performance in ADAS and new markets. In the ADAS market, a number of competitors have already achieved substantial market share using camera and radar-based perception sensing solutions, although we believe we offer a higher performance product that empowers higher performance ADAS systems, which we believe have the potential to displace current offerings and increase our market share. 
Market Opportunity
Our technology enables autonomy and can create new markets. Traditionally, many autonomous and 3D vision-based sensing applications were developed by utilizing non-lidar sensors; however, as the benefits of lidar-based solutions are becoming more widely recognized, we believe there are significant market opportunities available for our technology. As autonomous and 3D vision-based applications continue to grow more complex, we believe our technologies will become increasingly adopted due to our innovation, leadership, scale, and commercial readiness.
We expect demand in the automotive market to be driven by regulatory and customer demand for lidar solutions. Based on third party data, we estimate that the total market size for vehicles deploying autonomous technology will be approximately 29.0 million vehicles by 2022 and approximately 52.8 million vehicles by 2026. Generally, the number of lidar sensors to be deployed on each vehicle in the market depends on the level of autonomy and the type of lidar sensors utilized, which we expect to range from one to 12 sensors in 2022 and one to 13 sensors in 2026. We believe that in most cases that more lidar sensors, or at least lidar sensors with greater functionality, will be required as the level of autonomy increases towards full autonomy. In addition to the automotive market, we believe there are significant market opportunities available for our technology in the industrial, drones, autonomous mobile robots and 3D mapping end-markets that we are actively engaging with customers on. In addition, we believe that our market opportunity could be larger than what is currently estimated as there are early development and largely unexplored new and emerging applications, which we refer to as greenfield applications, such as traffic monitoring, pedestrian monitoring, security and natural disaster damage assessment.
Sales and Marketing
We continue expanding our sales and marketing efforts to attract new customers and grow orders from existing customers. We have developed a global network of active distributors to sell, install and support our solutions. Our channel partner ecosystem helps develop emerging applications for our lidar technology.
We have launched Automated with Velodyne program, our integrator ecosystem aimed to commercialize next generation autonomous solutions using our lidar technology. Through the program, we help companies by supporting innovation, promoting applications and creating lasting customer and business relationships. The program reflects our focus on accelerating market adoption of 3D lidar innovations and driving revenue growth for our partners around the world. In addition to a broad portfolio of groundbreaking, versatile lidar sensors, we provide technical, sales and distribution channel service and support. The program includes joint marketing activities to promote partner brands and customer success at trade shows, social and owned media channels, and more. There are over 75 companies in the Automated with Velodyne program. They have used our lidar technologies to build solutions in application areas that include ADAS, autonomous vehicles, mapping, industrial, smart city, drone/UAV, robotics and security.
Through our marketing efforts and strategic relationships we also continue to expand our global network of customers and channel partners. We are well known to global automotive OEMs, Tier 1 suppliers and customers using 3D lidar for non-automotive use cases, including mapping applications, UAVs, robotics, smart cities and industrial applications. These relationships allow us to continue to reach additional customers and partners globally. We also leverage opportunities to present and speak at conferences, executive events, trade shows and industry events to further develop our brand and reputation. These opportunities also allow us to showcase our technology and attract additional customer and channel partner interest. Through industry events and strategic relationships, we continue to identify the evolving needs of our customers and, as a result, develop new and improved solutions. 
Research and Development
We have invested a significant amount of time and expense into research and development of lidar-based technologies. Our ability to maintain our leadership position depends in part on our ongoing research and development activities. Our research and development team is responsible for the design, development, manufacturing and testing of our products. We focus our efforts on development in the areas of novel lidar architecture, advanced product design, innovative manufacturing technologies and advanced algorithms. In addition, we are transitioning from field programmable gate arrays to application-specific integrated circuits (ASICs) in order to further improve performance of our products, lower costs and reduce reliance on any key suppliers. 
Our research and development is largely conducted at our headquarters in San Jose, California. As of December 31, 2020, we had approximately 123 full time employees engaged in our research and development activities.
Intellectual Property
Our ability to be at the forefront of innovation in the lidar market depends in part on our ability to obtain and maintain patents and other proprietary rights relating to our key technology, and our ability to successfully enforce these rights against third parties. We currently have proprietary intellectual property, including in our embedded software, real-time 3D vision for autonomous systems, manufacturing processes and calibration methodology, which we believe is strongly protected by our registered patents. We have also filed patents and trademark applications in order to further secure these rights and strengthen our ability to defend against third parties who may infringe on our rights. We also protect our proprietary rights through agreements with our customers and channel partners.
As of December 31, 2020, we had 21 issued and 8 allowed U.S. patents and 41 pending U.S. patent applications. These issued patents begin expiring in 2027. We also have in the aggregate 158 issued non-U.S. patents, pending Patent Cooperation Treaty (PCT) applications and non-U.S. national stage applications corresponding to various U.S. patent applications described above.
The applications and issued patents cover a broad range of system level and component level aspects of lidar technology. We do not know whether any of our pending patent applications will result in the issuance of patents or whether the 
examination process will require us to narrow our claims. Even if granted, there is no assurance that these pending patent applications will provide us with protection.
Government Regulation
We are subject to the requirements under the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010 that will require us to diligence, disclose and report whether our products contain conflict minerals. The implementation of these requirements could adversely affect the sourcing, availability and pricing of the materials used in the manufacture of components used in our products.
In addition, our operations are subject to various international, federal, state and local laws and regulations governing the occupational health and safety of our employees and wage regulations. We are subject to the requirements of the federal Occupational Safety and Health Act, as amended, (“OSHA”), and comparable international, state and local laws that protect and regulate employee health and safety.
At both the federal and state level, the U.S. has provided a positive legal environment to permit safe testing and development of autonomous functionality. We do not anticipate any near-term federal standards that would impede the foreseeable deployments of our lidar technology. Some states, however, particularly California and New York, still enforce certain operational or registration requirements for certain autonomous functions. We believe such hurdles will be removed as state regulators gain better experience with the technology. U.S. federal regulations, however, remain largely permissive of deployments of higher levels of safe and responsible autonomous functionality.
At the federal level in the U.S., the safety of the automotive industry is regulated by the U.S. Department of Transportation through two federal Agencies – the National Highway Traffic Safety Administration (the “NHTSA”) and the Federal Motor Carrier Safety Administration. NHTSA establishes the Federal Motor Vehicle Safety Standards (the “FMVSS”) for motor vehicles and motor vehicle equipment and oversees the actions that manufacturers of motor vehicles and motor vehicle equipment are required to take regarding the reporting of information related to defects or injuries related to their products and the recall and repair of vehicles and equipment that contain safety defects or fail to comply with the FMVSS. 
As the cars that carry our sensors go into production, we are subject to existing stringent requirements under the National Traffic and Motor Vehicle Safety Act of 1966 (the “Vehicle Safety Act”), including a duty to report, subject to strict timing requirements overseen by NHTSA, safety defects with our products. The Vehicle Safety Act imposes potentially significant civil penalties for violations including the failure to comply with such reporting requirements. We are also subject to the existing U.S. Transportation Recall Enhancement, Accountability and Documentation Act (“TREAD”), which requires equipment manufacturers, such as us, to comply with “Early Warning” requirements by reporting certain information to the NHTSA, such as information related to defects or reports of injury related to our products. TREAD imposes criminal liability for violating such requirements if a defect subsequently causes death or bodily injury. In addition, the National Traffic and Motor Vehicle Safety Act authorizes NHTSA to require a manufacturer to recall and repair vehicles that contain safety defects or fail to comply with U.S. federal motor vehicle safety standards. Sales into foreign countries may be subject to similar regulations. As the development of federal and state regulation of autonomous machines and vehicles continues to evolve, we may be subject to additional regulatory schemes.
In addition, we are subject to the Electronic Product Radiation Control Provisions of the Federal Food, Drug, and Cosmetic Act. These requirements are enforced by the U.S. Food and Drug Administration (“FDA”). Electronic product radiation includes laser technology. Regulations governing these products are intended to protect the public from hazardous or unnecessary exposure. Manufacturers are required to certify in product labeling and reports to the FDA that their products comply with applicable performance standards as well as maintain manufacturing, testing, and distribution records for their products.
In order for us to operate in international markets outside the U.S., we may also be required to comply with relevant federal and foreign legal regulations regarding autonomous vehicles as well as technology export control, data security, cybersecurity, the International Traffic in Arms Regulation promulgated under the Arms Export Control Act (“ITAR”), the Foreign Corrupt Practices Act (“FCPA”), the anti-boycott provisions of the U.S. Export Administration Act  and other related regulations that apply to global technology companies. We have developed compliance processes and procedures related to these regulatory requirements and believe that we are in compliance with such requirements. We do not believe there are any regulatory restrictions that would materially restrict our ability to operate in our key markets. 
Human Capital Resources
As of December 31, 2020, we employed approximately 309 people. We also engage numerous consultants and contractors to supplement our permanent workforce. None of our employees are represented by a labor union or covered by collective bargaining agreements. We believe we have strong and positive relations with our employees. We are focused on aligning our valued human capital resources to our strategic priorities with a strong focus on leadership development, employee engagement and company culture. As part of our commitment to employee development, we make ongoing investments in our team, including hiring a Chief People Officer in October 2020 to lead our global human resources organization.
Our company culture is focused on honesty, integrity, dignity and respect, and our Code of Conduct is designed to help us achieve the right results, the right way. The code establishes high standards of honesty and integrity for all employees, officers and directors, and expects the same high standards of contractors, consultants, suppliers and agents. The specific policies set forth in the code help ensure that we conduct our business fairly and ethically in an environmentally responsible and sustainable manner.
